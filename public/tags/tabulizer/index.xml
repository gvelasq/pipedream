<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
  <title>tabulizer on %&gt;% dreams</title>
  <link>/tags/tabulizer/</link>
  <description>Recent content in tabulizer on %&gt;% dreams</description>
  <generator>Hugo -- gohugo.io</generator>
<language>en-us</language>
<lastBuildDate>Sun, 16 Dec 2018 00:00:00 +0000</lastBuildDate><atom:link href="/tags/tabulizer/index.xml" rel="self" type="application/rss+xml" />
<item>
  <title>Transforming PDF&#39;s into Useful Tables</title>
  <link>/blog/snap-expenditures/</link>
  <pubDate>Sun, 16 Dec 2018 00:00:00 +0000</pubDate>
  
<guid>/blog/snap-expenditures/</guid>
  <description>


&lt;p&gt;Way back in 2016, the USDA released a &lt;a href=&#34;https://www.fns.usda.gov/snap/foods-typically-purchased-supplemental-nutrition-assistance-program-snap-households&#34;&gt;study&lt;/a&gt; entitled “Foods Typically Purchased by Supplemental Nutrition Assistance Program (SNAP) Households,” including a summary, final report, and appendices. Per the USDA’s description:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This study uses calendar year 2011 point-of-sale transaction data from a leading grocery retailer to examine the food choices of SNAP and non-SNAP households.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;At the time though, I was most interested in looking at the &lt;a href=&#34;https://fns-prod.azureedge.net/sites/default/files/ops/SNAPFoodsTypicallyPurchased-Appendices.pdf&#34;&gt;appendices data&lt;/a&gt; - &lt;em&gt;263&lt;/em&gt; pages full of tables detailing the commodities and categories of food bought by both families served and not served by SNAP. Unfortunately, these wonderful data are in PDF format, with ‘fancy’ Excel formatting (merged cells, unnecessary column names), where the formatting varies depending on which appendix you are looking at.&lt;/p&gt;
&lt;p&gt;I &lt;a href=&#34;mailto:SNAPHQ-WEB@fns.usda.gov&#34;&gt;emailed&lt;/a&gt; SNAP HQ to ask if they had the raw data available in CSV’s and was told simply:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thank you for your inquiry. Unfortunately we do not have the data tables in a CSV file.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;At the time, my R skills were pretty rudimentary and I couldn’t figure out how to easily and efficiently pull the data into usable tables. Two years later and with a little more experience with R and scraping and cleaning ugly files, I decided to try again using the wonderful &lt;code&gt;tidyverse&lt;/code&gt; and &lt;code&gt;tabulizer&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tabulizer)
library(broom)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use &lt;code&gt;tabulizer::extract_tables()&lt;/code&gt; to extract the data from the &lt;a href=&#34;https://fns-prod.azureedge.net/sites/default/files/ops/SNAPFoodsTypicallyPurchased-Appendices.pdf&#34;&gt;appendices PDF&lt;/a&gt;. Once you extract the tables, you are left with a list (slightly more manageable than the original PDFs).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snap_pdf &amp;lt;-
  extract_tables(&amp;quot;https://fns-prod.azureedge.net/sites/default/files/ops/SNAPFoodsTypicallyPurchased-Appendices.pdf&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the &lt;code&gt;purrr&lt;/code&gt; package, create a data frame from the lists while simultaneously removing the unnecessary rows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snap_df &amp;lt;- 
  snap_pdf %&amp;gt;%
  map(as_tibble) %&amp;gt;%
  map_df(~ slice(., -2)) # slicing because of the unnecessary rows
  
head(snap_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 9
##   V1        V2    V3                    V4    V5    V6    V7    V8    V9   
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;                 &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 &amp;quot;&amp;quot;        &amp;quot;&amp;quot;    &amp;quot;SNAP Household Expe~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt; 
## 2 Soft dri~ &amp;quot;&amp;quot;    1 $357.7 5.44% 2 $1,~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt; 
## 3 Fluid mi~ &amp;quot;&amp;quot;    2 $253.7 3.85% 1 $1,~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt; 
## 4 Beef:gri~ &amp;quot;&amp;quot;    3 $201.0 3.05% 6 $62~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt; 
## 5 Bag snac~ &amp;quot;&amp;quot;    4 $199.3 3.03% 5 $79~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt; 
## 6 Cheese    &amp;quot;&amp;quot;    5 $186.4 2.83% 3 $94~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Due to the original formatting of the PDFs, there’s a bunch of cleaning to be done to make the list into a usable table. Using &lt;code&gt;slice()&lt;/code&gt;, I choose only the rows from Appendix 1. I manually put in the number of entries (238) because I didn’t know how to calculate this using code. If you have ideas, let me know!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snap_appendix1 &amp;lt;-
  snap_df %&amp;gt;% 
  slice(1:238) # Appendix A has 238 rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now comes the fun part (yay data cleaning!). When looking at the data frame, the data for each commodity are all mushed together in two separate columns (V2 and V3), but only one column or the other. Then there are a bunch of empty columns (V4 through V9), probably created from the funky original formatting. The data all begin with numbers as well. First things first - put all the data in a single column. Then, remove all the empty rows in the newly created &lt;code&gt;col_dat&lt;/code&gt; column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snap_appendix1_cleaned &amp;lt;-
  snap_appendix1 %&amp;gt;%
  mutate(col_dat = case_when(grepl(&amp;quot;[0-9]&amp;quot;, V2) ~ V2, # create a column that contains all the data
                           grepl(&amp;quot;[0-9]&amp;quot;, V3) ~ V3,
                           TRUE ~ &amp;quot;&amp;quot;)) %&amp;gt;% 
  filter(col_dat != &amp;quot;&amp;quot;) # some rows are empty

head(snap_appendix1_cleaned)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 10
##   V1       V2    V3         V4    V5    V6    V7    V8    V9    col_dat    
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;      
## 1 Soft dr~ &amp;quot;&amp;quot;    1 $357.7 ~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  1 $357.7 5~
## 2 Fluid m~ &amp;quot;&amp;quot;    2 $253.7 ~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  2 $253.7 3~
## 3 Beef:gr~ &amp;quot;&amp;quot;    3 $201.0 ~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  3 $201.0 3~
## 4 Bag sna~ &amp;quot;&amp;quot;    4 $199.3 ~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  4 $199.3 3~
## 5 Cheese   &amp;quot;&amp;quot;    5 $186.4 ~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  5 $186.4 2~
## 6 Baked b~ &amp;quot;&amp;quot;    6 $163.7 ~ &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  6 $163.7 2~&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the numeric data we want is wonderfully in a single column, so we can select the columns &lt;code&gt;V1&lt;/code&gt; and &lt;code&gt;col_dat&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snap_appendix1_cleaned &amp;lt;-
  snap_appendix1_cleaned %&amp;gt;% 
  select(V1, col_dat)

head(snap_appendix1_cleaned)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   V1                  col_dat                        
##   &amp;lt;chr&amp;gt;               &amp;lt;chr&amp;gt;                          
## 1 Soft drinks         1 $357.7 5.44% 2 $1,263.3 4.01%
## 2 Fluid milk products 2 $253.7 3.85% 1 $1,270.3 4.03%
## 3 Beef:grinds         3 $201.0 3.05% 6 $621.1 1.97%  
## 4 Bag snacks          4 $199.3 3.03% 5 $793.9 2.52%  
## 5 Cheese              5 $186.4 2.83% 3 $948.9 3.01%  
## 6 Baked breads        6 $163.7 2.49% 4 $874.8 2.78%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All the numeric data is still mushed in column &lt;code&gt;col_dat&lt;/code&gt;, so using &lt;code&gt;tidyr::separate()&lt;/code&gt; we can split the values because they are all separated by spaces. Referencing the original PDF, we descriptively rename the columns (and rename the commodity column &lt;code&gt;V1&lt;/code&gt; as well). The numeric values have retained their original formatting, with dollar signs and commas and percentage signs, oh my! We can sub out those unnecessary characters and transform those columns into truly numeric values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snap_appendix1_cleaned &amp;lt;-
  snap_appendix1_cleaned %&amp;gt;%
  separate(col_dat, &amp;quot; &amp;quot;,
           into = c(&amp;quot;snap_rank&amp;quot;, &amp;quot;snap_dollars_in_millions&amp;quot;, &amp;quot;snap_pct_total_expenditures&amp;quot;, &amp;quot;nonsnap_rank&amp;quot;, &amp;quot;nonsnap_dollars_in_millions&amp;quot;, &amp;quot;nonsnap_pct_total_expenditures&amp;quot;)) %&amp;gt;%
  rename(commodity = V1) %&amp;gt;%
  mutate_at(vars(snap_rank:nonsnap_pct_total_expenditures), list(~ as.numeric(gsub(&amp;quot;,|%|\\$&amp;quot;, &amp;quot;&amp;quot;, .))))

head(snap_appendix1_cleaned)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   commodity snap_rank snap_dollars_in~ snap_pct_total_~ nonsnap_rank
##   &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1 Soft dri~         1             358.             5.44            2
## 2 Fluid mi~         2             254.             3.85            1
## 3 Beef:gri~         3             201              3.05            6
## 4 Bag snac~         4             199.             3.03            5
## 5 Cheese            5             186.             2.83            3
## 6 Baked br~         6             164.             2.49            4
## # ... with 2 more variables: nonsnap_dollars_in_millions &amp;lt;dbl&amp;gt;,
## #   nonsnap_pct_total_expenditures &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Last but not least, we convert all the columns with percentages into actual percentages by dividing by 100.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snap_appendix1_cleaned &amp;lt;-
  snap_appendix1_cleaned %&amp;gt;%
  mutate_at(vars(contains(&amp;quot;pct&amp;quot;)), list(~ ./100))

head(snap_appendix1_cleaned)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   commodity snap_rank snap_dollars_in~ snap_pct_total_~ nonsnap_rank
##   &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1 Soft dri~         1             358.           0.0544            2
## 2 Fluid mi~         2             254.           0.0385            1
## 3 Beef:gri~         3             201            0.0305            6
## 4 Bag snac~         4             199.           0.0303            5
## 5 Cheese            5             186.           0.0283            3
## 6 Baked br~         6             164.           0.0249            4
## # ... with 2 more variables: nonsnap_dollars_in_millions &amp;lt;dbl&amp;gt;,
## #   nonsnap_pct_total_expenditures &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tada! Now we have a clean dataset from the original not-very-usable PDFs.&lt;/p&gt;
&lt;p&gt;Another goal is to at some point do a full analysis of what these data show. My hope is that now some of it is available, others can create and share amazing analysis with it. For the purposes of this blogpost, here are some quick ggplots comparing the rank of commodities between families served by SNAP and those who are not.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snap_appendix1_cleaned %&amp;gt;% # quick correlation plot
 ggplot(aes(x = snap_rank, y = nonsnap_rank)) +
 geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/snap-expenditures_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snap_lm &amp;lt;- lm(snap_rank ~ nonsnap_rank, data = snap_appendix1_cleaned)
snap_res &amp;lt;- augment(snap_lm)

snap_res %&amp;gt;% # quick residual plot
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/snap-expenditures_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I’d love to collaborate with others to finish up this project and find efficiencies. The repo with the code and final dataset is &lt;a href=&#34;https://github.com/ivelasq/snap&#34;&gt;here&lt;/a&gt;. More to come!&lt;/p&gt;
</description>
  </item>
  
<item>
  <title>Disaggregating Minneapolis Public Schools Data</title>
  <link>/blog/why-disaggregate-data/</link>
  <pubDate>Fri, 21 Sep 2018 00:00:00 +0000</pubDate>
  
<guid>/blog/why-disaggregate-data/</guid>
  <description>&lt;p&gt;Although this post heavily references education and student data, the principle of using distributions is paramount in any field that strives to close equity gaps.&lt;/p&gt;
&lt;div id=&#34;what-is-equity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is Equity&lt;/h2&gt;
&lt;p&gt;Inequities are &lt;a href=&#34;http://www.yourdictionary.com/racial-inequality&#34;&gt;disparities in opportunity, resources, and treatment.&lt;/a&gt; Racial and socioeconomic inequities are those that are as a result of one’s race or socioeconomic status. The unequal distribution of opportunity, resource, and treatment can be due to many factors, including patterns in society. &lt;a href=&#34;https://www.allsides.com/dictionary/racial-inequity&#34;&gt;Examples include:&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Racial attitudes/bias that act subtly to undermine and exclude,&lt;/li&gt;
&lt;li&gt;Continued redlining in lending,&lt;/li&gt;
&lt;li&gt;Embedded biases in education (images, language, school discipline),&lt;/li&gt;
&lt;li&gt;Long term ramifications of poor health/healthcare.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because the definition of equity varies from team to team, it is important to decide which inequities to identify and focus on.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-disaggregated-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What Is Disaggregated Data&lt;/h2&gt;
&lt;p&gt;According to the &lt;a href=&#34;https://www.edglossary.org/disaggregated-data/&#34;&gt;Glossary of Education Reform&lt;/a&gt;, the formal definition of disaggregated data is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Disaggregated data refers to numerical or non-numerical information that has been (1) collected from multiple sources and/or on multiple measures, variables, or individuals; (2) compiled into aggregate data—i.e., summaries of data—typically for the purposes of public reporting or statistical analysis; and then (3) broken down in component parts or smaller units of data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Aggregate population numbers are broken down into smaller groupings that analysts can compare and contrast. These groupings depend on your team’s definition of equity, whether it be focused on race, socioeconomic status, race AND socioeconomic status, age, ethnicity, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-use-disaggregated-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why Use Disaggregated Data&lt;/h2&gt;
&lt;p&gt;Particularly in education, disaggregated data is essential in identifying where solutions are needed to solve inequities. Per NCES’ &lt;a href=&#34;https://nces.ed.gov/pubsearch/pubsinfo.asp?pubid=NFES2017017&#34;&gt;Forum Guide to Collecting and Using Disaggregated Data on Racial/Ethnic Subgroups&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Educators need both high-level data summaries as well as disaggregated data that accurately describe smaller groups of students they serve. Access to and analysis of more detailed data—that is, disaggregated data—can be a useful tool for improving educational outcomes for small groups of students who otherwise would not be distinguishable in the aggregated data used for federal reporting. Disaggregating student data into subpopulations can help schools and communities plan appropriate programs; decide which interventions to implement; target limited resources; and recognize trends in educational participation, outcomes, and achievement.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;minneapolis-public-schools-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Minneapolis Public Schools Example&lt;/h2&gt;
&lt;p&gt;Minneapolis Public Schools (MPS) reports their student demographics in a robust, complete way. Not only do they report the percentage of students in a subgroup, but they also include the number of students in each subgroup. This allows a deep look into their individual school demographics and gives us the opportunity to explore equity in their district.&lt;/p&gt;
&lt;div id=&#34;pulling-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Pulling Data&lt;/h3&gt;
&lt;p&gt;All code to pull MPS data is included in the code appendix. MPS has moved to publishing their school data in PDFs. Thankfully, the &lt;code&gt;tabulizer&lt;/code&gt; package exists! It easily and quickly pulled the data into lists which I then transformed to data frames and tidied up.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;first-glance-mps-district-demographics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;First Glance: MPS District Demographics&lt;/h3&gt;
&lt;p&gt;Here is a barplot which shows the percentage of different subgroups in the school district. FRPL stands for Free/Reduced Price Lunch, often used as a proxy for poverty. Students from a household with an income up to 185 percent of the poverty threshold are eligible for free or reduced price lunch. (Sidenote: Definitions are very important in disaggregated data. FRPL is used because it’s ubiquitous and reporting is mandated but &lt;a href=&#34;https://nces.ed.gov/blogs/nces/post/free-or-reduced-price-lunch-a-proxy-for-poverty&#34;&gt;there is debate as to whether it actually reflects the level of poverty among students&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/why-disaggregate-data_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When we look at these data, MPS looks like a diverse school district. Almost &lt;strong&gt;40% of students are Black&lt;/strong&gt; and around &lt;strong&gt;35% are White&lt;/strong&gt;. &lt;strong&gt;60% of the students are eligible for FRPL&lt;/strong&gt;, which is &lt;a href=&#34;https://nces.ed.gov/programs/digest/d17/tables/dt17_204.10.asp?current=yes&#34;&gt;high for Minnesota but close to the US average of 52.1%&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, let’s explore if there’s more to this story.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;discover-distributions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Discover Distributions&lt;/h3&gt;
&lt;p&gt;Another view of the data can be visualizing the distribution of percentage of a demographic within schools. Here is a histogram for the percentage of White students within the 74 MPS schools for which we have data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/why-disaggregate-data_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;27 of the 74 (36%) of schools have between 0-10% White students.&lt;/strong&gt; This implies that even though the school district may be diverse, the demographics are not evenly distributed across the schools. More than half of schools enroll fewer than 30% of White students even though White students make up 35% of the district student population.&lt;/p&gt;
&lt;p&gt;The school race demographics are not representative of the district populations but does that hold for socioeconomic status as well?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-categories&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create Categories&lt;/h3&gt;
&lt;p&gt;High-poverty schools are defined as public schools where more than 75% of the students are eligible for FRPL. According to NCES, &lt;a href=&#34;https://nces.ed.gov/fastfacts/display.asp?id=898&#34;&gt;24% of public school students attended high-poverty schools&lt;/a&gt;. However, different subgroups were overrepresented and underrepresented within the high poverty schools. Is this the case for MPS?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/why-disaggregate-data_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9% of White students&lt;/strong&gt; attend high poverty schools, compared to &lt;strong&gt;46% of Black students&lt;/strong&gt;, &lt;strong&gt;51% of Hispanic students&lt;/strong&gt;, &lt;strong&gt;46% of Asian students&lt;/strong&gt;, and &lt;strong&gt;49% of Native American students&lt;/strong&gt;. These students are disproportionally attending high poverty schools.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reveal-relationships&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reveal Relationships&lt;/h3&gt;
&lt;p&gt;Let’s explore what happens when we correlate race and FRPL percentage by school.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/why-disaggregate-data_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Similarly to the result above, &lt;strong&gt;there is a strong negative correlation between FRPL percentage and the percentage of white students in a school.&lt;/strong&gt; High poverty schools have a lower percentage of White students and low poverty schools have a higher percentage of White students.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;According to the Urban Institute, the disproportionate percentage of students of color attending high poverty schools “is a defining feature of almost all Midwestern and northeastern metropolitan school systems.” Among other issues, high poverty schools &lt;a href=&#34;https://www.urban.org/urban-wire/high-poverty-schools-undermine-education-children-color&#34;&gt;tend to lack the educational resources—like highly qualified and experienced teachers, low student-teacher ratios, college prerequisite and advanced placement courses, and extracurricular activities—available in low-poverty schools.&lt;/a&gt; This has a huge impact on these students and their futures.&lt;/p&gt;
&lt;p&gt;Because of the disaggregated data Minneapolis Public Schools provides, we can go deeper than the average of demographics across the district and see what it looks like on the school level. These views display that (1) there exists a distribution of race/ethnicity within schools that are not representative of the district, (2) that students of color are overrepresented in high poverty schools, and (3) there is a relationship between the percentage of White students in a school and the percentage of students eligible for FRPL.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;amazing-examples-of-disaggregated-data-reporting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Amazing Examples of Disaggregated Data Reporting&lt;/h2&gt;
&lt;p&gt;There are so many amazing examples out there using disaggregated data. These two are my favorites:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nytimes.com/interactive/2016/04/29/upshot/money-race-and-success-how-your-school-district-compares.html&#34;&gt;Money, Race and Success: How Your School District Compares&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.tampabay.com/projects/2015/investigations/pinellas-failure-factories/chart-failing-black-students/&#34;&gt;Why Pinellas County is the worst place in Florida to be black and go to public school&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;code-appendix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Code Appendix&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(viridis)
library(tabulizer)
library(janitor)

# race data
race_pdf &amp;lt;-
  extract_tables(&amp;quot;http://studentaccounting.mpls.k12.mn.us/uploads/racial_ethnic_school_gradefall2017.pdf&amp;quot;)

race_df &amp;lt;- # many thanks to my brother @gvelasq for purrrifying this
  race_pdf %&amp;gt;%
  map(as_tibble) %&amp;gt;%
  map_df(~ slice(., -1:-2)) %&amp;gt;% 
  set_names(c(&amp;quot;school_group&amp;quot;, &amp;quot;school_name&amp;quot;, &amp;quot;grade&amp;quot;, &amp;quot;na_num&amp;quot;, &amp;quot;na_pct&amp;quot;, &amp;quot;aa_num&amp;quot;, &amp;quot;aa_pct&amp;quot;, &amp;quot;as_num&amp;quot;, &amp;quot;as_pct&amp;quot;, &amp;quot;hi_num&amp;quot;, &amp;quot;hi_pct&amp;quot;, &amp;quot;wh_num&amp;quot;, &amp;quot;wh_pct&amp;quot;, &amp;quot;pi_pct&amp;quot;, &amp;quot;blank_col&amp;quot;, &amp;quot;tot&amp;quot;))

race_filter &amp;lt;-
  race_df %&amp;gt;%
  select(-school_group, -grade, -pi_pct, -blank_col) %&amp;gt;% # unnecessary or blank columns
  filter(str_detect(school_name, &amp;quot;Total&amp;quot;),
         school_name != &amp;quot;Grand Total&amp;quot;) %&amp;gt;% # otherwise totals are duplicated
  mutate(school_name = str_replace(school_name, &amp;quot;Total&amp;quot;, &amp;quot;&amp;quot;)) %&amp;gt;% 
  mutate_if(is.character, trimws) 

# frpl data
frpl_pdf &amp;lt;-
  extract_tables(&amp;quot;http://studentaccounting.mpls.k12.mn.us/uploads/free_reduced_meal_fall_2017.pdf&amp;quot;)

frpl_df &amp;lt;- # many thanks to my brother @gvelasq for purrrifying this
  frpl_pdf %&amp;gt;%
  map(as_tibble) %&amp;gt;%
  map_df(~ slice(., -1)) %&amp;gt;%  
  set_names(c(&amp;quot;school_grades&amp;quot;, &amp;quot;school_name&amp;quot;, &amp;quot;total_students&amp;quot;, &amp;quot;frpl_pct&amp;quot;, &amp;quot;free_num&amp;quot;, &amp;quot;reduce_num&amp;quot;, &amp;quot;not_eligible_num&amp;quot;))

frpl_filter &amp;lt;-
  frpl_df %&amp;gt;% 
  filter(school_name != &amp;quot;&amp;quot;) %&amp;gt;%
  select(-school_grades)

# merged data
merged_df &amp;lt;-
  left_join(race_filter, frpl_filter, by = c(&amp;quot;school_name&amp;quot;)) %&amp;gt;% 
  mutate_at(2:17, as.numeric) %&amp;gt;%
  mutate(frpl_pct = (free_num + reduce_num)/total_students,
         hi_povnum = case_when(frpl_pct &amp;gt; .75 ~ hi_num),
         aa_povnum = case_when(frpl_pct &amp;gt; .75 ~ aa_num),
         wh_povnum = case_when(frpl_pct &amp;gt; .75 ~ wh_num),
         as_povnum = case_when(frpl_pct &amp;gt; .75 ~ as_num),
         na_povnum = case_when(frpl_pct &amp;gt; .75 ~ na_num)) %&amp;gt;%
  adorn_totals() %&amp;gt;%
  mutate(na_pct = na_num/tot,
         aa_pct = aa_num/tot,
         as_pct = as_num/tot,
         hi_pct = hi_num/tot,
         wh_pct = wh_num/tot,
         frpl_pct = (free_num + reduce_num)/total_students, # otherwise total frpl_pct is off
         hi_povsch = hi_povnum/hi_num[which(school_name == &amp;quot;Total&amp;quot;)],
         aa_povsch = aa_povnum/aa_num[which(school_name == &amp;quot;Total&amp;quot;)],
         as_povsch = as_povnum/as_num[which(school_name == &amp;quot;Total&amp;quot;)],
         wh_povsch = wh_povnum/wh_num[which(school_name == &amp;quot;Total&amp;quot;)],
         na_povsch = na_povnum/na_num[which(school_name == &amp;quot;Total&amp;quot;)])

# tidy data
tidy_df &amp;lt;-
  merged_df %&amp;gt;%
  gather(category, value, -school_name)

# this is so I do not have to run the code above constantly
tidy_df &amp;lt;- read_csv(here::here(&amp;quot;content&amp;quot;, &amp;quot;blog&amp;quot;, &amp;quot;why_disaggregate_data_files&amp;quot;, &amp;quot;tidy_df.csv&amp;quot;))
merged_df &amp;lt;- read_csv(here::here(&amp;quot;content&amp;quot;, &amp;quot;blog&amp;quot;, &amp;quot;why_disaggregate_data_files&amp;quot;, &amp;quot;merged_df.csv&amp;quot;))
# demographic barplot
tidy_df %&amp;gt;%
  filter(school_name == &amp;quot;Total&amp;quot;,
         str_detect(category, &amp;quot;pct&amp;quot;)) %&amp;gt;% 
  mutate(category = factor(category, levels = c(&amp;quot;aa_pct&amp;quot;, &amp;quot;wh_pct&amp;quot;, &amp;quot;hi_pct&amp;quot;, &amp;quot;as_pct&amp;quot;, &amp;quot;na_pct&amp;quot;, &amp;quot;frpl_pct&amp;quot;))) %&amp;gt;%  
  ggplot(aes(x = category, y = value)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, aes(fill = factor(category))) +
  xlab(&amp;quot;Subgroup&amp;quot;) +
  ylab(&amp;quot;Percentage of Population&amp;quot;) +
  scale_x_discrete(labels = c(&amp;quot;Black&amp;quot;, &amp;quot;White&amp;quot;, &amp;quot;Hispanic&amp;quot;, &amp;quot;Asian&amp;quot;, &amp;quot;Native Am.&amp;quot;, &amp;quot;FRPL&amp;quot;)) +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_viridis(option = &amp;quot;cividis&amp;quot;, discrete = T) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)

# histogram
merged_df %&amp;gt;% 
  filter(school_name != &amp;quot;Total&amp;quot;) %&amp;gt;% 
  ggplot(aes(x = wh_pct)) +
  geom_histogram(fill = &amp;quot;slategray4&amp;quot;, breaks= seq(0, 1, by = .1)) +
  xlab(&amp;quot;White Percentage&amp;quot;) +
  ylab(&amp;quot;Count&amp;quot;) +
  scale_x_continuous(labels = scales::percent) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)

# histogram info
histinfo &amp;lt;- hist(merged_df$wh_pct)
histinfo

# high poverty barplot
tidy_df %&amp;gt;%
  filter(school_name == &amp;quot;Total&amp;quot;,
         str_detect(category, &amp;quot;povsch&amp;quot;)) %&amp;gt;% 
  mutate(category = factor(category, levels = c(&amp;quot;hi_povsch&amp;quot;, &amp;quot;na_povsch&amp;quot;, &amp;quot;aa_povsch&amp;quot;, &amp;quot;as_povsch&amp;quot;, &amp;quot;wh_povsch&amp;quot;))) %&amp;gt;%  
  ggplot(aes(x = category, y = value)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, aes(fill = factor(category))) +
  xlab(&amp;quot;Subgroup&amp;quot;) +
  ylab(&amp;quot;Percentage in High Poverty Schools&amp;quot;) +
  scale_x_discrete(labels = c(&amp;quot;Hispanic&amp;quot;, &amp;quot;Native Am.&amp;quot;, &amp;quot;Black&amp;quot;, &amp;quot;Asian&amp;quot;, &amp;quot;White&amp;quot;)) +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_viridis(option = &amp;quot;cividis&amp;quot;, discrete = T) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)

# scatterplot
merged_df %&amp;gt;% 
  filter(school_name != &amp;quot;Total&amp;quot;) %&amp;gt;% 
  ggplot(aes(x = wh_pct, y = frpl_pct)) +
  geom_point(color = &amp;quot;slategray4&amp;quot;) +
  xlab(&amp;quot;White Percentage&amp;quot;) +
  ylab(&amp;quot;FRPL Percentage&amp;quot;) +
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(labels = scales::percent) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
  </item>
  
</channel>
  </rss>