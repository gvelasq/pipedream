<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on %&gt;% dreams</title>
    <link>/categories/r/</link>
    <description>Recent content in R on %&gt;% dreams</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 30 Aug 2020 00:00:00 +0000</lastBuildDate><atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Even Easier-to-Use R Package for School District Shapefiles</title>
      <link>/blog/leaidr2/</link>
      <pubDate>Sun, 30 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/leaidr2/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/mapdeck-binding/mapdeck.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/mpadeck_functions/mapdeck_functions.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/deckgl/deckgl.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/legend/legend.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/title/title.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/mapdeck_location/mapdeck_location.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/mapdeck_colours/mapdeck_colours.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/mapdeck_coordinates/mapdeck_coordinates.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/mapboxgl/mapbox-gl.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/mapboxgl/mapbox-gl.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/mapdeck/mapdeck.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/mpadeck-binding/mapdeck.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;leaidr-update&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;leaidr Update&lt;/h2&gt;
&lt;p&gt;A few months ago, I created &lt;a href=&#34;https://github.com/ivelasq/leaidr&#34;&gt;{leaidr}&lt;/a&gt; for easier download of U.S. school district shapefiles. &lt;a href=&#34;https://github.com/datalorax&#34;&gt;Daniel Anderson&lt;/a&gt; went through and greatly improved the package, making it even easier to download and use the shapefiles (thanks Dan!).&lt;/p&gt;
&lt;p&gt;Now, instead of having to run &lt;code&gt;lea_prep()&lt;/code&gt;, you can download the shapefiles from Dan’s Github repository like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(leaidr)

tn &amp;lt;- lea_get(&amp;quot;tn&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## OGR data source with driver: ESRI Shapefile 
## Source: &amp;quot;/private/var/folders/pj/nmg9b8_93dq4kwt8nt2d4cj40000gn/T/RtmpCFlfFo/47&amp;quot;, layer: &amp;quot;47&amp;quot;
## with 158 features
## It has 18 fields&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tn %&amp;gt;% 
  sf::st_as_sf() %&amp;gt;% 
  ggplot2::ggplot() +
  ggplot2::geom_sf()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/leaidr2_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And, if you use &lt;code&gt;lea_get()&lt;/code&gt; (i.e., with &lt;code&gt;state = NULL&lt;/code&gt;), you’ll get the shapefiles for the whole U.S. back via ROpenSci’s {piggyback}.&lt;/p&gt;
&lt;p&gt;So much easier and better!&lt;/p&gt;
&lt;p&gt;Because Dan helped make the package so great, I wanted to add on and showcase what can be done with it! So, today’s post is jam-packed with choices…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#create-a-beautiful-map-in-mapbox&#34;&gt;Create a Beautiful Map in Mapbox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#create-a-shiny-app-with-your-beautiful-map&#34;&gt;Create a Shiny App with Your Beautiful Maps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#add-a-shiny-app-to-the-package&#34;&gt;Add A Shiny App to the Package&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-beautiful-map-in-mapbox&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create a Beautiful Map in Mapbox&lt;/h2&gt;
&lt;p&gt;Asmae Toumi wrote a &lt;a href=&#34;https://asmae-toumi.netlify.app/posts/2020-08-10-how-to-make-web-ready-us-county-level-maps/&#34;&gt;blog post&lt;/a&gt; on how to make maps using R and Mapbox. So, I figured: why not announce the new and improved {leaidr} functions to create a beautiful Mapbox map??&lt;/p&gt;
&lt;p&gt;This walkthrough will go a little deeper with Mapbox, as I am an extreme beginner and had to do a lot of investigating to figure out how to use it.&lt;/p&gt;
&lt;p&gt;I suggest first reading through Asmae’s tutorial as there are a few things you need to do before being able to run the below: download the {mapboxapi} package, create a Mapbox account, and install Tippecanoe.&lt;/p&gt;
&lt;div id=&#34;load-the-libraries&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Load the Libraries&lt;/h3&gt;
&lt;p&gt;Here are the libraries you will need:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

# remotes::install_github(&amp;quot;walkerke/mapboxapi&amp;quot;)
library(mapboxapi)

# if you haven&amp;#39;t installed the package yet
# devtools::install_github(&amp;quot;ivelasq/leaidr&amp;quot;)
library(leaidr)

library(rmapshaper)
library(mapdeck)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;download-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Download the Data&lt;/h3&gt;
&lt;p&gt;Download your shapefiles. If you want to make a choropleth map, also read in the data that you will append to your shapefiles and merge them together by a common ID. (Sorry for using a local file!)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;shp &amp;lt;- # leaidr shapefiles
  lea_get(c(&amp;quot;or&amp;quot;, &amp;quot;wa&amp;quot;)) %&amp;gt;% 
  sf::st_as_sf()

dat &amp;lt;- # data to append 
  read_csv(&amp;quot;/Users/shortessay/Downloads/ccd_lea_141_1819_l_1a_091019/ccd_lea_141_1819_l_1a_091019.csv&amp;quot;) %&amp;gt;%
  filter(ST %in% c(&amp;quot;OR&amp;quot;, &amp;quot;WA&amp;quot;))

northwest &amp;lt;-
  shp %&amp;gt;%
  select(GEOID, geometry) %&amp;gt;%
  sp::merge(dat, by.x = &amp;quot;GEOID&amp;quot;, by.y = &amp;quot;LEAID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;create-the-tileset&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create the Tileset&lt;/h3&gt;
&lt;p&gt;Now, following the original tutorial, we use Tippecanoe to optimize the shapefiles and data and then upload the “tiles” to Mapbox.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tippecanoe(
  input = northwest,
  output = &amp;quot;nw.mbtiles&amp;quot;,
  layer_name = &amp;quot;northwest&amp;quot;)

upload_tiles(input = &amp;quot;nw.mbtiles&amp;quot;,
             username = &amp;quot;ivelasq3&amp;quot;, 
             tileset_id = &amp;quot;northwest&amp;quot;,
             multipart = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;style-the-tiles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Style the Tiles&lt;/h3&gt;
&lt;p&gt;This is the part that I had to figure out on the Mapbox website. &lt;a href=&#34;https://docs.mapbox.com/help/tutorials/choropleth-studio-gl-pt-1/&#34;&gt;This&lt;/a&gt; walkthrough was helpful. Once you have uploaded the tiles using &lt;code&gt;upload_tiles()&lt;/code&gt;, you should see them available under “Custom tileset” at the bottom of this webpage: &lt;a href=&#34;https://studio.mapbox.com/tilesets/&#34; class=&#34;uri&#34;&gt;https://studio.mapbox.com/tilesets/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/mapbox_files/1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Then, go to Styles on this webpage: &lt;a href=&#34;https://studio.mapbox.com/&#34; class=&#34;uri&#34;&gt;https://studio.mapbox.com/&lt;/a&gt;. Click “New Style” and choose the template you want, then Customize.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/mapbox_files/2.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To add your tileset, go to Layers, click the Plus sign, then under “Source”, find your uploaded tileset or add the tileset by the ID given by &lt;code&gt;upload_tiles()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/mapbox_files/3.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I zoomed to where my tiles are located (Oregon and Washington) and started editing. &lt;a href=&#34;https://docs.mapbox.com/help/tutorials/choropleth-studio-gl-pt-1/#data-driven-styling&#34;&gt;This section of the walkthrough&lt;/a&gt; explains how to create a choropleth map, where each geography has a different color according to a value.&lt;/p&gt;
&lt;p&gt;Once done styling, I clicked “Publish” on the top right of Mapbox Studio.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-map-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using Map in R&lt;/h3&gt;
&lt;p&gt;To get the information to bring it back into R and be able to use the map in a Shiny app, I clicked “Share” and scrolled to find the Style ID.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/mapbox_files/4.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I copied the Share URL to include in the function below. For the location parameter, I used the latitude/longitude listed in the browser URL. I played around with the zoom level until I found one I liked.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mapdeck(token = Sys.getenv(&amp;quot;MAPBOX_PUBLIC_TOKEN&amp;quot;),
        style = &amp;quot;mapbox://styles/ivelasq3/ckehhzzld3l3p19mht1n8hksj&amp;quot;,
        zoom = 4,
        location = c(-120.161, 45.843))&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:672px;height:480px;&#34; class=&#34;mapdeck html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;access_token&#34;:&#34;pk.eyJ1IjoiaXZlbGFzcTMiLCJhIjoiY2tlNmJpaHlrMWJpbjJ2cDgzczRpbjNpMSJ9.YMLVVVzPxfnms4oADrG0aQ&#34;,&#34;style&#34;:&#34;mapbox://styles/ivelasq3/ckehhzzld3l3p19mht1n8hksj&#34;,&#34;pitch&#34;:0,&#34;zoom&#34;:4,&#34;location&#34;:[-120.161,45.843],&#34;bearing&#34;:0,&#34;max_zoom&#34;:20,&#34;min_zoom&#34;:0,&#34;max_pitch&#34;:60,&#34;min_pitch&#34;:0,&#34;show_view_state&#34;:false,&#34;repeat_view&#34;:false},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-shiny-app-with-your-beautiful-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create a Shiny App with Your Beautiful Map&lt;/h2&gt;
&lt;p&gt;Once you have the &lt;code&gt;mapdeck()&lt;/code&gt; function all set up, you can use it in a Shiny app. &lt;a href=&#34;https://github.com/greghuang8/Geovis/blob/master/shinyApp.R&#34;&gt;Here’s&lt;/a&gt; some reference code that I found useful for using &lt;code&gt;renderMapdeck()&lt;/code&gt;. Thank you Greg Huang!&lt;/p&gt;
&lt;p&gt;This is an example of a very bare bones Shiny app. For the UI, use &lt;code&gt;mapdeckOutput()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(shiny)
library(mapdeck)

ui &amp;lt;- fluidPage(
  mapdeckOutput(outputId = &amp;quot;createMap&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And for the server, paste the &lt;code&gt;mapdeck()&lt;/code&gt; function in &lt;code&gt;renderMapdeck()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;server &amp;lt;- function(input, output) {

  output$createMap &amp;lt;- renderMapdeck({
    mapdeck(token = Sys.getenv(&amp;quot;MAPBOX_PUBLIC_TOKEN&amp;quot;),
            style = &amp;quot;mapbox://styles/ivelasq3/ckehhzzld3l3p19mht1n8hksj&amp;quot;,
            zoom = 4,
            location = c(-120.161, 45.843))
  })
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I uploaded the bare bones app &lt;a href=&#34;https://ivelasq.shinyapps.io/leaidr/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;add-a-shiny-app-to-the-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Add A Shiny App to the Package&lt;/h2&gt;
&lt;p&gt;Now, say you would like to add the Shiny app to your package as well as upload to shinyapps.io / instead of uploading to shinyapps.io. Thankfully, Dean Attali has a &lt;a href=&#34;https://deanattali.com/2015/04/21/r-package-shiny-app/&#34;&gt;great walkthrough&lt;/a&gt; on how to do this!&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Add {shiny} to your dependencies in your &lt;code&gt;DESCRIPTION&lt;/code&gt; file (I do this with &lt;code&gt;usethis::use_package(&#34;shiny&#34;)&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Create a folder called &lt;code&gt;inst&lt;/code&gt; in your package with another folder for the Shiny example, and your UI/server file(s) within.&lt;/li&gt;
&lt;li&gt;Create an R file to run your example (I used &lt;code&gt;usethis::use_r(&#34;runExample.R&#34;)&lt;/code&gt;) to create this file.&lt;/li&gt;
&lt;li&gt;Don’t forget to document! &lt;code&gt;devtools::document()&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, if you were to install and load {leaidr}, you can run &lt;code&gt;leaidr::runExample()&lt;/code&gt; to launch the Shiny app. To see what the files look like, check out the Github repo files &lt;a href=&#34;https://github.com/ivelasq/leaidr/tree/master/inst/shiny-examples/mapbox&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In conclusion, {leaidr} can help you map your data as long as you have school district LEAID’s or names in there somewhere. I hope that it helps you in your education data projects!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Websites &amp; Apps</title>
      <link>/itemized/apps/</link>
      <pubDate>Sun, 12 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/itemized/apps/</guid>
      <description>


&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#blogdown&#34;&gt;Blogdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bookdown&#34;&gt;Bookdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#shiny&#34;&gt;Shiny&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;blogdown&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Blogdown&lt;/h1&gt;
&lt;div id=&#34;r-ladies-seattle-website&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R-Ladies Seattle Website&lt;/h2&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/seattle.png&#34; /&gt;&lt;/p&gt;
&lt;a href=&#34;https://rladiesseattle.org/&#34; class=&#34;uri&#34;&gt;https://rladiesseattle.org/&lt;/a&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;bookdown&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bookdown&lt;/h1&gt;
&lt;div id=&#34;data-science-in-education-using-r-open-version&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Science in Education Using R Open Version&lt;/h2&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/dsieur.png&#34; /&gt;&lt;/p&gt;
&lt;a href=&#34;https://datascienceineducation.com/&#34; class=&#34;uri&#34;&gt;https://datascienceineducation.com/&lt;/a&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;shiny&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Shiny&lt;/h1&gt;
&lt;div id=&#34;spurious-covid-correlation-creator&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Spurious COVID Correlation Creator&lt;/h2&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/corr.png&#34; /&gt;&lt;/p&gt;
&lt;a href=&#34;https://ivelasq.shinyapps.io/SpuriousCOVIDCorrelationCreator/&#34; class=&#34;uri&#34;&gt;https://ivelasq.shinyapps.io/SpuriousCOVIDCorrelationCreator/&lt;/a&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What It Takes to Tidy Census Data</title>
      <link>/blog/tidying-census-data/</link>
      <pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/tidying-census-data/</guid>
      <description>


&lt;p&gt;The U.S. Census releases aggregate data on their &lt;a href=&#34;https://www.census.gov/data/tables/2020/demo/hhp2.html&#34;&gt;Household Pulse Survey&lt;/a&gt;. These data are super interesting and cover a range of important topics, particularly those related to the COVID-19 pandemic.&lt;/p&gt;
&lt;p&gt;First of all, let me clarify that I think that the work that the Census does is amazing and I am so glad that these data are available. But, when you download the data, you will see that it is a highly stylized Excel spreadsheet. There may be upsides for those who want to see the data quickly and easily. As an R user though, seeing all those merged cells, non-numerics numerics, and category names in rows makes me feel &lt;code&gt;emo::ji(&#39;unamused&#39;)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/census_files/census_image.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;However, this is not terribly surprising (and with public data, somewhat expected). As stated in the &lt;a href=&#34;https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html&#34;&gt;tidy data&lt;/a&gt; paper:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It is often said that 80% of data analysis is spent on the cleaning and preparing data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Thankfully, we have the very powerful R and tidyverse available to address our data woes. Let’s go through the process of tidying these data with tidyverse packages to show how easily they can become Ready for analysis!&lt;/p&gt;
&lt;div id=&#34;loading-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Loading the Data&lt;/h2&gt;
&lt;p&gt;Per usual, we begin by loading our necessary libraries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(readxl)
library(httr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An option to download the Excel file and loading it in R. What if we want to load the data directly from the website? We can use {httr}! The following code ‘gets’ the file from the internet, writes it in a temporary file path, and loads it in an object called &lt;code&gt;path&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Many thanks to Liz Potamites for pointing out: if the below doesn’t work, it may be that the link is changed or broken. It should be Table 2 from the second week of the Household Pulse Survey, which as of July 21, 2020 is located &lt;a href=&#34;https://www.census.gov/data/tables/2020/demo/hhp/hhp2.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;GET(&amp;quot;https://www2.census.gov/programs-surveys/demo/tables/hhp/2020/wk2/educ2_week2.xlsx&amp;quot;, write_disk(path &amp;lt;- tempfile(fileext = &amp;quot;.xlsx&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Response [https://www2.census.gov/programs-surveys/demo/tables/hhp/2020/wk2/educ2_week2.xlsx]
##   Date: 2020-07-22 03:02
##   Status: 200
##   Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
##   Size: 442 kB
## &amp;lt;ON DISK&amp;gt;  /var/folders/pj/nmg9b8_93dq4kwt8nt2d4cj40000gn/T//RtmpfjZc3y/file7f32106c6185.xlsx&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;cleaning-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cleaning the Data&lt;/h2&gt;
&lt;p&gt;As mentioned in the figure above, each sheet comprises of a state’s data. It’d be good to have all of the data in one single data structure. One option is to try to force all of the sheets together at once in a data frame (which is a 2D structure). But we also saw that each sheet requires a lot of cleaning before it can be useful, and it may be difficult to clean if they’re all merged in one data frame. Therefore, let’s instead first read in all the data as a &lt;strong&gt;list&lt;/strong&gt; (which is a higher dimension structure), clean it up, and &lt;em&gt;then&lt;/em&gt; put it together in a data frame.&lt;/p&gt;
&lt;p&gt;However, I am not very good at thinking about things in list format and it’s a little harder to see what’s going on compared to looking at a data frame using &lt;code&gt;View()&lt;/code&gt;. Before I clean up a list, I usually work on a single cut of the list as a data frame to know what exactly I am going to do. Thankfully, all the sheets in this Excel sheet are formatted the same across states. This isn’t always the case! Because they are identically formatted, we know if our processing works on one sheet, it will work across all of them.&lt;/p&gt;
&lt;p&gt;Let’s look at a single sheet!&lt;/p&gt;
&lt;div id=&#34;single-sheet-cleaning&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Single Sheet Cleaning&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_sheet1 &amp;lt;-
  read_excel(path, sheet = 1)

View(census_sheet1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/census_files/census1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Immediately, we see that the top lines are superfluous rows (the headers from the original dataset). We can use &lt;code&gt;skip&lt;/code&gt; in &lt;code&gt;read_excel()&lt;/code&gt; to not have them read in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_sheet1 &amp;lt;-
  read_excel(path, sheet = 1, skip = 3)

# View(census_sheet1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/census_files/census2.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now that the unnecessary rows are gone, we see that the column names aren’t reading in super well because of the merged cells in the original sheet. In this case, we manually create a vector of the column names and replace the old ones with &lt;code&gt;set_names()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_names &amp;lt;-
  c(&amp;quot;select_characteristics&amp;quot;, &amp;quot;total&amp;quot;, &amp;quot;using_online_resources&amp;quot;, &amp;quot;using_paper_materials_sent_home&amp;quot;, &amp;quot;where_classes_were_cancelled&amp;quot;, &amp;quot;where_classes_changed_in_another_way&amp;quot;, &amp;quot;where_no_change_to_classes&amp;quot;, &amp;quot;did_not_respond&amp;quot;)

census_example &amp;lt;-
  census_sheet1 %&amp;gt;% 
  set_names(new_names)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/census_files/census3.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We still have some empty rows (and also a row at the very bottom which is a note in the original dataset). We can eliminate these rows using &lt;code&gt;slice()&lt;/code&gt;. Here, we’re saying to ‘slice’ rows 1 through 3 and 60.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_example &amp;lt;-
  census_example %&amp;gt;% 
  slice(-1:-3, -60:-61)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/census_files/census4.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now to deal with the fact that the category names are embedded within the first column &lt;code&gt;select_characteristics&lt;/code&gt;. There may be other ways to do this, but again I manually create a vector with all the characteristic names that I want to get rid of and use &lt;code&gt;filter()&lt;/code&gt; to keep only the rows that do &lt;strong&gt;not&lt;/strong&gt; contain the items in the vector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter_var &amp;lt;- 
  c(&amp;quot;Age&amp;quot;, &amp;quot;Sex&amp;quot;, &amp;quot;Hispanic origin and Race&amp;quot;, &amp;quot;Education&amp;quot;, &amp;quot;Marital status&amp;quot;, &amp;quot;Presence of children under 18 years old&amp;quot;, &amp;quot;Respondent or household member experienced loss of employment income&amp;quot;, &amp;quot;Mean weekly hours spent on…&amp;quot;, &amp;quot;Respondent currently employed&amp;quot;, &amp;quot;Food sufficiency for households prior to March 13, 2020&amp;quot;, &amp;quot;Household income&amp;quot;)

census_example &amp;lt;-
  census_example %&amp;gt;% 
  filter(!select_characteristics %in% filter_var) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/census_files/census5.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Even though we removed the characteristic names from the rows, they actually contain very useful information. Also, we run into an issue in which two of the characteristic categories had the same options (“yes” and “no”). If we don’t address this, we’ll forget which rows are for which characteristic. To fix this, we manually create a column with the characteristics for each of the response options and append it to the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;category_column &amp;lt;-
  c(&amp;quot;age&amp;quot;, &amp;quot;age&amp;quot;, &amp;quot;age&amp;quot;, &amp;quot;age&amp;quot;, &amp;quot;age&amp;quot;, &amp;quot;sex&amp;quot;, &amp;quot;sex&amp;quot;, &amp;quot;race&amp;quot;, &amp;quot;race&amp;quot;, &amp;quot;race&amp;quot;, &amp;quot;race&amp;quot;, &amp;quot;race&amp;quot;, &amp;quot;education&amp;quot;, &amp;quot;education&amp;quot;, &amp;quot;education&amp;quot;, &amp;quot;education&amp;quot;, &amp;quot;marital_status&amp;quot;, &amp;quot;marital_status&amp;quot;, &amp;quot;marital_status&amp;quot;, &amp;quot;marital_status&amp;quot;, &amp;quot;marital_status&amp;quot;, &amp;quot;children&amp;quot;, &amp;quot;children&amp;quot;, &amp;quot;loss_employment&amp;quot;, &amp;quot;loss_employment&amp;quot;, &amp;quot;loss_employment&amp;quot;, &amp;quot;hours_spent&amp;quot;, &amp;quot;hours_spent&amp;quot;, &amp;quot;employed&amp;quot;, &amp;quot;employed&amp;quot;, &amp;quot;employed&amp;quot;, &amp;quot;food_sufficiency&amp;quot;, &amp;quot;food_sufficiency&amp;quot;, &amp;quot;food_sufficiency&amp;quot;, &amp;quot;food_sufficiency&amp;quot;, &amp;quot;food_sufficiency&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;income&amp;quot;)

census_example &amp;lt;-
  census_example %&amp;gt;% 
  add_column(category_column)&lt;/code&gt;&lt;/pre&gt;
&lt;center&gt;
&lt;img src=&#34;https://ivelasq.rbind.io/img/census_files/census6.png&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Finally, you may have noticed that some of the rows did not read in as numbers but as characters.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;https://ivelasq.rbind.io/img/census_files/census7.png&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;We can use &lt;code&gt;mutate_at()&lt;/code&gt; and specify which variables we want to be numeric.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_example &amp;lt;-
  census_example %&amp;gt;% 
  mutate_at(vars(total, using_online_resources:did_not_respond), list(~ as.numeric(.)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hooray - now we have a tidy dataset we could use for analysis! Which is great, but it’s only one sheet. How do we do this for the additional 66?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multi-sheet-cleaning&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multi Sheet Cleaning&lt;/h3&gt;
&lt;p&gt;We will now download the data and store it in a list, where each sheet (which represents a state) is saved as a tibble within the list. To work across all the lists, we use the tidyverse package {purrr} and its handy functions.&lt;/p&gt;
&lt;p&gt;You may notice that the multi sheet cleaning looks a lot like the single sheet cleaning but everything is wrapped in the function &lt;code&gt;map()&lt;/code&gt;. That’s true! The wonderful thing about {purrr} being in the tidyverse is that it’s really easy to integrate with all the tidyverse functions.&lt;/p&gt;
&lt;p&gt;Reading the data into one list is slightly more complicated than reading in a single sheet. We begin with the file path from before and then use &lt;code&gt;excel_sheets()&lt;/code&gt; to create a vector of the sheet names. &lt;code&gt;set_names()&lt;/code&gt; ensures that we have a named list that contains the state names, which will be important later. If we don’t use &lt;code&gt;set_names()&lt;/code&gt;, then the tibbles have generic names instead of ‘US’, ‘AL’, etc. Then using &lt;code&gt;purrr::map()&lt;/code&gt;, we ask R to download each of the sheets of the dataset and store it together in a list (&lt;code&gt;map()&lt;/code&gt; always returns a list).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_list &amp;lt;-
  path %&amp;gt;% 
  excel_sheets() %&amp;gt;% 
  set_names() %&amp;gt;% 
  map(~ read_excel(path = path, sheet = .x, skip = 3), .id = &amp;quot;Sheet&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you take a look at the list using &lt;code&gt;View(census_list)&lt;/code&gt;, you can see the data is stored as tibbles within the list. If you expand &lt;code&gt;US&lt;/code&gt;, you’ll see the same data as when we did the single sheet example. You can also see the same data if you run &lt;code&gt;census_list[[&#34;US&#34;]]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/census_files/census_list.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Using the same thinking as we did with the single sheet example, let’s go through and clean up this list - without having to go into each individual tibble!&lt;/p&gt;
&lt;p&gt;First, we set the names within each list using &lt;code&gt;set_names()&lt;/code&gt;. We tell &lt;code&gt;map()&lt;/code&gt; the names of the columns by defining &lt;code&gt;nm&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_list &amp;lt;- 
  census_list %&amp;gt;% 
  map(., set_names, nm = new_names)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For each tibble in the list (&lt;code&gt;.x&lt;/code&gt;), remove the rows 1 through 3 and 60.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_list &amp;lt;- 
  census_list %&amp;gt;% 
  map(~ slice(.x, -1:-3, -60:-61))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now for each tibble, filter out the rows in &lt;code&gt;select_characteristics&lt;/code&gt; that contain the items in &lt;code&gt;filter_var&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_list &amp;lt;- 
  census_list %&amp;gt;% 
  map(~ filter(.x, !select_characteristics %in% filter_var))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Like before, we want a new column that lets us know the category for each of the characteristic options.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_list &amp;lt;- 
  census_list %&amp;gt;% 
  map(~ add_column(.x, category_column))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And like before, we want to make sure our numeric columns are actually numeric.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_list &amp;lt;- 
  census_list %&amp;gt;% 
  map(~ mutate_at(.x, vars(total, using_online_resources:did_not_respond), list(~ as.numeric(.))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that our tibbles are all clean and uniform, let’s make this a single, 2D data frame! Like I mentioned before, it’s important that our list is named with the state abbreviations. We can use &lt;code&gt;map_df()&lt;/code&gt; to create a data frame with an ID column called &lt;code&gt;state&lt;/code&gt; that stores each of the sheet names. With this column, we’ll easily know which column is for which state/geography.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_df &amp;lt;- 
  census_list %&amp;gt;% 
  map_df(~ as.data.frame(.x), .id = &amp;quot;state&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Congrats! We have successfully tidied a Census dataset!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using the Data&lt;/h2&gt;
&lt;p&gt;The purpose of all this work is to be able to use it easily in R and with the tidyverse specifically. Let’s use the plotting package {ggplot2} to make something!&lt;/p&gt;
&lt;p&gt;According to the Census website, we can calculate percentages by removing those that did not respond from the total for the denominator (let’s presume that NA in the column means that everybody responded). Let’s say we want to see the proportion of respondents in the U.S. who say their classes were cancelled by income level.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census_us_income &amp;lt;-
  census_df %&amp;gt;% 
  filter(state == &amp;quot;US&amp;quot;, category_column == &amp;quot;income&amp;quot;) %&amp;gt;% 
  mutate(responses = case_when(!is.na(did_not_respond) ~ total - did_not_respond, 
                               is.na(did_not_respond) ~ total),# calculate denominator
         pct_cancelled = where_classes_were_cancelled / responses) # calculate percentage

census_us_income &amp;lt;- # setting factor levels so graph shows correct order
  census_us_income %&amp;gt;% 
  mutate(select_characteristics = factor(select_characteristics,
                                         levels = c(&amp;quot;Less than $25,000&amp;quot;, 
                                                    &amp;quot;$25,000 - $34,999&amp;quot;,
                                                    &amp;quot;$35,000 - $49,999&amp;quot;,
                                                    &amp;quot;$50,000 - $74,999&amp;quot;,
                                                    &amp;quot;$75,000 - $99,999&amp;quot;,
                                                    &amp;quot;$100,000 - $149,999&amp;quot;,
                                                    &amp;quot;$150,000 - $199,999&amp;quot;,
                                                    &amp;quot;$200,000 and above&amp;quot;)))

census_us_income %&amp;gt;% 
  filter(select_characteristics != &amp;quot;Did not report&amp;quot;) %&amp;gt;% 
  ggplot(aes(x = select_characteristics, y = pct_cancelled)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;,
           fill = &amp;quot;#265B5F&amp;quot;) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = &amp;quot;Percent of Respondents Whose Children&amp;#39;s Classes Were Cancelled&amp;quot;,
       x = &amp;quot;Income&amp;quot;,
       y = &amp;quot;Percent with Classes Cancelled&amp;quot;,
       caption = &amp;quot;Source: U.S. Census&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/tidying-census-data_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From this graph, we can see that respondents from the lower income bands were more likely to say that classes were cancelled for their children due to COVID.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>packages</title>
      <link>/itemized/packages/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/itemized/packages/</guid>
      <description>


&lt;center&gt;
&lt;p&gt;&lt;strong&gt;wizehiver:&lt;/strong&gt; R wrapper for WizeHive’s Zengine API&lt;/p&gt;
&lt;a href=&#34;https://github.com/ivelasq/wizehiver&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://image.ibb.co/hkekzT/hex_Sticker_nospot_copy.png&#34; height=&#34;120&#34; /&gt;&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;p&gt;&lt;strong&gt;dataedu:&lt;/strong&gt; R Package Associated with the Data Science in Education Using R Book&lt;/p&gt;
&lt;a href=&#34;https://github.com/data-edu&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/ivelasq/dataedu/blob/master/man/figures/logo.png?raw=true&#34; height=&#34;120&#34; /&gt;&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;p&gt;&lt;strong&gt;leaidr:&lt;/strong&gt; R Package for U.S. School District Shapefiles&lt;/p&gt;
&lt;a href=&#34;https://github.com/ivelasq/leaidr&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/ivelasq/leaidr/blob/master/man/figures/logo.png?raw=true&#34; height=&#34;120&#34; /&gt;&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;p&gt;&lt;strong&gt;edreportr:&lt;/strong&gt; R Wrapper for EdReports API&lt;/p&gt;
&lt;a href=&#34;https://github.com/MarkLaVenia/edreportr&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/MarkLaVenia/edreportr/blob/master/man/figures/logo.png?raw=true&#34; height=&#34;120&#34; /&gt;&lt;/a&gt;
&lt;/center&gt;
</description>
    </item>
    
    <item>
      <title>Creating an R Package for School District Shapefiles</title>
      <link>/blog/leaid-shapefiles/</link>
      <pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/leaid-shapefiles/</guid>
      <description>


&lt;p&gt;I would like to introduce &lt;a href=&#34;https://github.com/ivelasq/leaidr&#34;&gt;{leaidr}&lt;/a&gt;, a package for mapping U.S. School District shapefiles!&lt;/p&gt;
&lt;p&gt;Inspired by my coauthor &lt;a href=&#34;https://joshuamrosenberg.com/&#34;&gt;Joshua Rosenberg&lt;/a&gt;, the goal of {leaidr} is to facilitate the download and use of school district shapefiles.&lt;/p&gt;
&lt;p&gt;School districts in the U.S. have associated local education agency identification numbers (LEAID) used in the &lt;a href=&#34;https://nces.ed.gov/pubs2010/100largest0809/tables/table_d05.asp&#34;&gt;National Center for Education Statistics (NCES) Common Core of Data&lt;/a&gt;. These are very useful because if you have other datasets with NCES ID’s, then you can (sometimes easily) join them.&lt;/p&gt;
&lt;p&gt;It can be very useful to visualize districts and associated data. District shapefiles are available in different places, such as through the &lt;a href=&#34;https://nces.ed.gov/programs/edge/Geographic/DistrictBoundaries&#34;&gt;NCES&lt;/a&gt; and &lt;a href=&#34;https://exhibits.stanford.edu/data/catalog/db586ns4974&#34;&gt;Stanford Education Data Archive&lt;/a&gt;. The package {tigris} also has a school district option, but unfortunately it is missing a few district polygons.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tigris)

ca &amp;lt;- tigris::school_districts(state = &amp;quot;06&amp;quot;,
                               type = &amp;quot;unified&amp;quot;)

plot(ca[&amp;quot;GEOID&amp;quot;])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/leaid-shapefiles_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;{leaidr} downloads NCES’ U.S. district shapefile from Github using ROpenSci’s &lt;a href=&#34;https://github.com/ropensci/piggyback&#34;&gt;{piggyback}&lt;/a&gt; package. This is a super helpful package, as Github caps file uploads at 100 MB (and the shapefile is ~170 MB). I originally tried Github Large File Storage (LFS), but it stores files as a hash, not as an actual file. Therefore, I couldn’t figure out how to use it for a package that others can use.&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;lea_get()&lt;/code&gt; downloads an R Data file from the Github repo to your designated path and then writes the necessary shapefiles. Then, create an object with &lt;code&gt;lea_prep()&lt;/code&gt; by designating where the shapefiles exist and which state(s) you would like. &lt;strong&gt;Note:&lt;/strong&gt; For now, you must use the state’s FIPS code. FIPS state codes are numeric and two-letter alphabetic codes to identify U.S. states and certain other associated areas. A reference table is found &lt;a href=&#34;https://www.mcc.co.mercer.pa.us/dps/state_fips_code_listing.htm&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once you have the shapefile, then you can merge with other datasets and plot using packages like {leaflet} and {ggplot2}.&lt;/p&gt;
&lt;div id=&#34;example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example&lt;/h2&gt;
&lt;p&gt;Let’s walk through an example where we will merge external data to the shapefile and then map all the districts in California. The external data is from Josh’s &lt;a href=&#34;https://github.com/making-data-science-count/covidedu&#34;&gt;&lt;code&gt;covidedu&lt;/code&gt; project&lt;/a&gt;, which scrapes district websites for specific words. In this case, the search terms were “covid*”, “coron*”, and “closure”. I highly recommend using &lt;code&gt;covidedu&lt;/code&gt; for easy scraping from a &lt;strong&gt;lot&lt;/strong&gt; of district websites!&lt;/p&gt;
&lt;p&gt;First, let’s call our libraries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
# if you haven&amp;#39;t installed the package yet
# devtools::install_github(&amp;quot;ivelasq/leaidr&amp;quot;)
library(leaidr)
library(maptools)
library(viridis)
# if you don&amp;#39;t have this downloaded
# install.packages(&amp;quot;mapproj&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Time to get your data! Use {leaidr} to download and prep your shapefiles for California (FIPS == 06). Read in the external data (in this case, &lt;code&gt;summary-of-table-of-links.csv&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You must have a GitHub PAT set to run &lt;code&gt;lea_get()&lt;/code&gt;. &lt;a href=&#34;https://happygitwithr.com/github-pat.html&#34;&gt;Happy git with R&lt;/a&gt; has a great walkthrough on how to do that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# download the shapefile into a designated folder
leaidr::lea_get(path = &amp;quot;./test&amp;quot;)

# prep the shapefile for the state(s) you&amp;#39;d like
ca_shapefile &amp;lt;-
  leaidr::lea_prep(path = &amp;quot;./test&amp;quot;, fips = &amp;quot;06&amp;quot;)

# read in the external data that also has NCES ID&amp;#39;s
# this is from the covidedu project
ca_data &amp;lt;-
  read_csv(&amp;quot;https://raw.githubusercontent.com/making-data-science-count/covidedu/master/output/2020-04-29/summary-of-table-of-links.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Join the CSV to the shapefile.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ca_merge &amp;lt;-
  sp::merge(ca_shapefile, ca_data, by.x = &amp;quot;GEOID&amp;quot;, by.y = &amp;quot;nces_id&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now ‘fortify’ the data - this converts the polygons into points. This is so ggplot can create the plot.&lt;/p&gt;
&lt;p&gt;If you get the error &lt;code&gt;isTRUE(gpclibPermitStatus()) is not TRUE&lt;/code&gt;, then you need to enable &lt;code&gt;gpclib&lt;/code&gt; by running &lt;code&gt;gpclibPermit()&lt;/code&gt; (this is part of the {maptools} package, which should have been loaded above). Note that support for &lt;code&gt;gpclib&lt;/code&gt; will be withdrawn from maptools at the next major release, so you might have to try something else if the package has been upgraded.&lt;/p&gt;
&lt;p&gt;If you run &lt;code&gt;gpclibPermit()&lt;/code&gt; and you keep getting &lt;code&gt;FALSE&lt;/code&gt;, then you are missing the package {gpclib}. Install the package, then run &lt;code&gt;gpclibPermit()&lt;/code&gt; to set it to &lt;code&gt;TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;(I don’t know if this is the best/only way to do this - if anybody has suggestions, please let me know!)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.package(&amp;quot;gpclib&amp;quot;)
gpclibPermit()
ca_points &amp;lt;- fortify(ca_merge, region = &amp;quot;GEOID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, join the points and the shapefile data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ca_df &amp;lt;- left_join(ca_merge@data, ca_points, by = c(&amp;quot;GEOID&amp;quot; = &amp;quot;id&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can finally plot the shapefile and its data!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ca_map &amp;lt;-
  ca_df %&amp;gt;% 
  ggplot() +
  geom_polygon(aes(x = long, 
                   y = lat, 
                   group = group,
                   fill = any_link_found),
               color = &amp;quot;gray&amp;quot;, 
               size = .2) +
  theme_void() +
  scale_fill_viridis(option = &amp;quot;cividis&amp;quot;, discrete = TRUE) +
  ggtitle(&amp;quot;COVID-Related Links Found on CA School District Sites&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make a nicer looking map, then you can use &lt;code&gt;coord_map()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map_projected &amp;lt;- ca_map +
  coord_map()

print(map_projected)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/leaid-shapefiles/test_map.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Tada! A full school district map for California.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;call-for-collaboration&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Call for Collaboration&lt;/h2&gt;
&lt;p&gt;Please try out {leaidr}! I hope that it is useful to you in your work. I’d love any collaborators to join me in making it easier/better!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Other functionalities&lt;/strong&gt;: Thinking of: being able to filter shapefiles by NCES IDs as well as states; adding commonly used data (like district demographics).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: If you run into any issues, please post on the &lt;a href=&#34;https://github.com/ivelasq/leaidr/issues&#34;&gt;GitHub page!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;resources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%20joining%20spatial%20data:%20http://www.nickeubank.com/wp-content/uploads/2015/10/RGIS2_MergingSpatialData_part1_Joins.html&#34;&gt;&lt;strong&gt;Joining Spatial Data&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rpubs.com/DanielSLee/censusMap&#34;&gt;&lt;strong&gt;Analyzing U.S. Census Data Using R&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Mise-en-Place: Everything in its Place</title>
      <link>/blog/mis-en-place/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/mis-en-place/</guid>
      <description>


&lt;p&gt;I got to be the &lt;span class=&#34;citation&#34;&gt;@WeAreRLadies&lt;/span&gt; curator for the week of February 10th and it was a great experience to get feedback from a wider swath of the R community. One question I posed was how people organize the folders within their projects, and I got a lot of engagement! For this blogpost, I categorize the common themes from these different resources and then list them all out at the end of the post.&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Alright everybody! What is your project folder structure? I want to shout out my &lt;a href=&#34;https://twitter.com/hashtag/rladies?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rladies&lt;/a&gt; co-organizer &lt;a href=&#34;https://twitter.com/chayacore?ref_src=twsrc%5Etfw&#34;&gt;@chayacore&lt;/a&gt; for creating this project skeleton 💀(and an awesome utilities package that creates it!) &lt;a href=&#34;https://t.co/8EzyAhkf2O&#34;&gt;pic.twitter.com/8EzyAhkf2O&lt;/a&gt;&lt;/p&gt;&amp;mdash; We are R-Ladies (@WeAreRLadies) &lt;a href=&#34;https://twitter.com/WeAreRLadies/status/1227575580171747333?ref_src=twsrc%5Etfw&#34;&gt;February 12, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;#resources&#34;&gt;Resources&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/moldach/project-directory&#34;&gt;Best Practices for Data Science Project Workflows and File Organization&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;resources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Breath of the Wild Weapon Dendrogram</title>
      <link>/blog/botw/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/botw/</guid>
      <description>



</description>
    </item>
    
    <item>
      <title>Six Things I Always Google When Using ggplot2</title>
      <link>/blog/things-i-google/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/things-i-google/</guid>
      <description>


&lt;p&gt;I often use {ggplot2} to create graphs but there are certain things I &lt;em&gt;always&lt;/em&gt; have to Google. I figured I’d create a post for quick reference for myself but I’d love to hear what you always have to look up!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#remove-the-legend&#34;&gt;Remove the Legend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#change-legend-title-and-labels&#34;&gt;Change Legend Title and Labels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#manually-change-colors&#34;&gt;Manually Change Colors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#remove-x-axis-labels&#34;&gt;Remove X Axis Labels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#start-the-y-axis-at-a-specific-number&#34;&gt;Start the Y Axis at a Specific Number&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#use-scales-on-the-y-axis&#34;&gt;Use Scales on the Y Axis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

knitr::opts_chunk$set(out.width = &amp;#39;100%&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To showcase what’s happening, I am going to use a &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday&#34;&gt;TidyTuesday&lt;/a&gt; dataset: Spotify songs! Let’s start by creating a simple graph.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load Data
spotify_songs &amp;lt;- 
  readr::read_csv(&amp;#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv&amp;#39;)

spotify_songs %&amp;gt;% 
  ggplot(aes(x = playlist_genre)) +
  geom_histogram(stat = &amp;quot;count&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/things-i-google_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;remove-the-legend&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Remove the legend&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;theme(legend.position = “none”)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ahh… this one always gets me. Sometimes when your color is mostly just for aesthetics, it doesn’t make sense to also have a color legend. This removes the legend and makes the graph look cleaner.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs %&amp;gt;% 
  ggplot(aes(x = playlist_genre, fill = playlist_genre)) +
  geom_histogram(stat = &amp;quot;count&amp;quot;) +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/things-i-google_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;change-legend-title-and-labels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Change Legend Title and Labels&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;scale_fill_discrete(name = “New Legend Title”, labels = c(“lab1” = “Label 1”, “lab2” = “Label 2”))&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Alright, say I do want the legend. How do I make it something readable?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs %&amp;gt;% 
  ggplot(aes(x = playlist_genre, fill = playlist_genre)) +
  geom_histogram(stat = &amp;quot;count&amp;quot;) +
  scale_fill_discrete(name = &amp;quot;Playlist Genre&amp;quot;, 
                      labels = c(&amp;quot;edm&amp;quot; = &amp;quot;EDM&amp;quot;, 
                                 &amp;quot;latin&amp;quot; = &amp;quot;Latin&amp;quot;, 
                                 &amp;quot;pop&amp;quot; = &amp;quot;Pop&amp;quot;, 
                                 &amp;quot;r&amp;amp;b&amp;quot; = &amp;quot;R&amp;amp;B&amp;quot;, 
                                 &amp;quot;rap&amp;quot; = &amp;quot;Rap&amp;quot;, 
                                 &amp;quot;rock&amp;quot; = &amp;quot;Rock&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/things-i-google_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;manually-change-colors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Manually Change Colors&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;scale_fill_manual(“New Legend Title”, values = c(“lab1” = “#000000”, “lab2” = “#FFFFFF”))&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is a bit tricker, in that you cannot use &lt;code&gt;scale_fill_manual&lt;/code&gt; and &lt;code&gt;scale_fill_discrete&lt;/code&gt; separately on the same plot as they override each other. However, if you want to change the labels &lt;em&gt;and&lt;/em&gt; the colors together, you can use &lt;code&gt;scale_fill_manual&lt;/code&gt; like below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs %&amp;gt;% 
  ggplot(aes(x = playlist_genre, fill = playlist_genre)) +
  geom_histogram(stat = &amp;quot;count&amp;quot;) +
  scale_fill_manual(name = &amp;quot;Playlist Genre&amp;quot;, 
                    labels = c(&amp;quot;edm&amp;quot; = &amp;quot;EDM&amp;quot;, 
                               &amp;quot;latin&amp;quot; = &amp;quot;Latin&amp;quot;, 
                               &amp;quot;pop&amp;quot; = &amp;quot;Pop&amp;quot;, 
                               &amp;quot;r&amp;amp;b&amp;quot; = &amp;quot;R&amp;amp;B&amp;quot;, 
                               &amp;quot;rap&amp;quot; = &amp;quot;Rap&amp;quot;, 
                               &amp;quot;rock&amp;quot; = &amp;quot;Rock&amp;quot;),
                    values = c(&amp;quot;edm&amp;quot; = &amp;quot;#68B39B&amp;quot;, 
                               &amp;quot;latin&amp;quot; = &amp;quot;#F6C7FF&amp;quot;, 
                               &amp;quot;pop&amp;quot; = &amp;quot;#ADFFE5&amp;quot;, 
                               &amp;quot;r&amp;amp;b&amp;quot; = &amp;quot;#CCB576&amp;quot;, 
                               &amp;quot;rap&amp;quot; = &amp;quot;#B3A070&amp;quot;, 
                               &amp;quot;rock&amp;quot; = &amp;quot;#d3d3d3&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/things-i-google_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;remove-x-axis-labels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Remove X Axis Labels&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;theme(axis.title.x = element_blank(),
axis.text.x = element_blank(),
axis.ticks.x = element_blank())&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this case, since we have a legend, we don’t need any x axis labels. Sometimes I use this if there’s redundant information or if it otherwise makes the graph look cleaner.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs %&amp;gt;% 
  ggplot(aes(x = playlist_genre, fill = playlist_genre)) +
  geom_histogram(stat = &amp;quot;count&amp;quot;) +
  scale_fill_manual(name = &amp;quot;Playlist Genre&amp;quot;, 
                    labels = c(&amp;quot;edm&amp;quot; = &amp;quot;EDM&amp;quot;, 
                               &amp;quot;latin&amp;quot; = &amp;quot;Latin&amp;quot;, 
                               &amp;quot;pop&amp;quot; = &amp;quot;Pop&amp;quot;, 
                               &amp;quot;r&amp;amp;b&amp;quot; = &amp;quot;R&amp;amp;B&amp;quot;, 
                               &amp;quot;rap&amp;quot; = &amp;quot;Rap&amp;quot;, 
                               &amp;quot;rock&amp;quot; = &amp;quot;Rock&amp;quot;),
                    values = c(&amp;quot;edm&amp;quot; = &amp;quot;#68B39B&amp;quot;, 
                               &amp;quot;latin&amp;quot; = &amp;quot;#F6C7FF&amp;quot;, 
                               &amp;quot;pop&amp;quot; = &amp;quot;#ADFFE5&amp;quot;, 
                               &amp;quot;r&amp;amp;b&amp;quot; = &amp;quot;#CCB576&amp;quot;, 
                               &amp;quot;rap&amp;quot; = &amp;quot;#B3A070&amp;quot;, 
                               &amp;quot;rock&amp;quot; = &amp;quot;#d3d3d3&amp;quot;)) +
  theme(axis.title.x = element_blank(),
         axis.text.x = element_blank(),
         axis.ticks.x = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/things-i-google_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;start-the-y-axis-at-a-specific-number&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Start the Y Axis at a Specific Number&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;scale_y_continuous(name = “New Y Axis Title”, limits = c(0, 1000000))&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Often times, we want our graph’s y axis to start at 0. In this example it already does, but this handy parameter allows us to set exactly what we want our y axis to be.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs %&amp;gt;% 
  ggplot(aes(x = playlist_genre, fill = playlist_genre)) +
  geom_histogram(stat = &amp;quot;count&amp;quot;) +
  scale_fill_manual(name = &amp;quot;Playlist Genre&amp;quot;, 
                    labels = c(&amp;quot;edm&amp;quot; = &amp;quot;EDM&amp;quot;, 
                               &amp;quot;latin&amp;quot; = &amp;quot;Latin&amp;quot;, 
                               &amp;quot;pop&amp;quot; = &amp;quot;Pop&amp;quot;, 
                               &amp;quot;r&amp;amp;b&amp;quot; = &amp;quot;R&amp;amp;B&amp;quot;, 
                               &amp;quot;rap&amp;quot; = &amp;quot;Rap&amp;quot;, 
                               &amp;quot;rock&amp;quot; = &amp;quot;Rock&amp;quot;),
                    values = c(&amp;quot;edm&amp;quot; = &amp;quot;#68B39B&amp;quot;, 
                               &amp;quot;latin&amp;quot; = &amp;quot;#F6C7FF&amp;quot;, 
                               &amp;quot;pop&amp;quot; = &amp;quot;#ADFFE5&amp;quot;, 
                               &amp;quot;r&amp;amp;b&amp;quot; = &amp;quot;#CCB576&amp;quot;, 
                               &amp;quot;rap&amp;quot; = &amp;quot;#B3A070&amp;quot;, 
                               &amp;quot;rock&amp;quot; = &amp;quot;#d3d3d3&amp;quot;)) +
  theme(axis.title.x = element_blank(),
         axis.text.x = element_blank(),
         axis.ticks.x = element_blank()) +
  scale_y_continuous(name = &amp;quot;Count&amp;quot;, limits = c(0, 10000))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/things-i-google_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-scales-on-the-y-axis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Use scales on the Y Axis&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;scale_y_continuous(label = scales::format)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Depending on our data, we may want the y axis to be formatted a certain way (using dollar signs, commas, percentage signs, etc.). The handy {scales} package allows us to do that easily.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spotify_songs %&amp;gt;% 
  ggplot(aes(x = playlist_genre, fill = playlist_genre)) +
  geom_histogram(stat = &amp;quot;count&amp;quot;) +
  scale_fill_manual(name = &amp;quot;Playlist Genre&amp;quot;, 
                    labels = c(&amp;quot;edm&amp;quot; = &amp;quot;EDM&amp;quot;, 
                               &amp;quot;latin&amp;quot; = &amp;quot;Latin&amp;quot;, 
                               &amp;quot;pop&amp;quot; = &amp;quot;Pop&amp;quot;, 
                               &amp;quot;r&amp;amp;b&amp;quot; = &amp;quot;R&amp;amp;B&amp;quot;, 
                               &amp;quot;rap&amp;quot; = &amp;quot;Rap&amp;quot;, 
                               &amp;quot;rock&amp;quot; = &amp;quot;Rock&amp;quot;),
                    values = c(&amp;quot;edm&amp;quot; = &amp;quot;#68B39B&amp;quot;, 
                               &amp;quot;latin&amp;quot; = &amp;quot;#F6C7FF&amp;quot;, 
                               &amp;quot;pop&amp;quot; = &amp;quot;#ADFFE5&amp;quot;, 
                               &amp;quot;r&amp;amp;b&amp;quot; = &amp;quot;#CCB576&amp;quot;, 
                               &amp;quot;rap&amp;quot; = &amp;quot;#B3A070&amp;quot;, 
                               &amp;quot;rock&amp;quot; = &amp;quot;#d3d3d3&amp;quot;)) +
  theme(axis.title.x = element_blank(),
         axis.text.x = element_blank(),
         axis.ticks.x = element_blank()) +
  scale_y_continuous(name = &amp;quot;Count&amp;quot;, limits = c(0, 10000),
                     labels = scales::comma)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/things-i-google_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There we have it! Six things I always eventually end up Googling when I am making plots using {ggplot2}. Hopefully now I can just look at this page instead of searching each and every time!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Finding the Modal School District</title>
      <link>/blog/modal-district/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/modal-district/</guid>
      <description>


&lt;p&gt;My good friend &lt;a href=&#34;https://twitter.com/RyanEs&#34;&gt;Ryan Estrellado&lt;/a&gt; recommended an &lt;a href=&#34;https://www.npr.org/2019/08/28/755191639/episode-936-the-modal-american&#34;&gt;NPR Planet Money podcast episode&lt;/a&gt; on the “Modal American.” Working with Ben Casselman, Planet Money explored the most ‘typical’ American. It was a fantastic, engaging episode about a common statistical technique that I’ve never seen applied in this way before. They ran the numbers on a variety of demographic variables to see what group is the most common in the U.S. (I highly recommend the episode - it’s pretty surprising!).&lt;/p&gt;
&lt;p&gt;Ben Casselman shared the &lt;a href=&#34;https://github.com/BenCasselman/planet_money&#34;&gt;code&lt;/a&gt; he ran for the analysis. Ryan suggested running a similar analysis to find the modal school district, which I thought was brilliant! The analysis is below, but if you are desperate for the answer, the modal school district in the U.S. is [drum roll please]: (1) Majority (&amp;gt;=50%) White, (2) Small, (3) Rural, and (4) Medium-Low FRPL (between 25% and 50% FRPL).&lt;/p&gt;
&lt;div id=&#34;downloading-and-parsing-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Downloading and Parsing Data&lt;/h2&gt;
&lt;p&gt;I used NCES &lt;a href=&#34;https://nces.ed.gov/ccd/ccddata.asp&#34;&gt;Common Core of Data (CCD)&lt;/a&gt; to pull Local Educational Agency (LEA) (a.k.a. school districts) demographic data. I wanted to try Urban Institute’s &lt;a href=&#34;https://github.com/UrbanInstitute/education-data-package-r&#34;&gt;{educationdata}&lt;/a&gt; R package. They have enrollment and racial demographic data available to download through their package. For Free/Reduced Price Lunch data, I had to pull the data directly from the CCD as it’s not available via the Urban API.&lt;/p&gt;
&lt;p&gt;What buckets do you choose for analysis? This is a bit tricky. I chose buckets I typically refer to for work. I also looked at some &lt;a href=&#34;https://nces.ed.gov/pubs2011/2011301.pdf&#34;&gt;NCES reports&lt;/a&gt; to see how they typically think about districts. Ultimately, I decided on four buckets: urban-centric locale bucket, race/ethnicity bucket, size bucket, and FRPL bucket.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(educationdata)
library(janitor)
library(ggalluvial)

knitr::opts_chunk$set(out.width = &amp;#39;100%&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;urban-centric-locale-bucket&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Urban-Centric Locale Bucket&lt;/h3&gt;
&lt;p&gt;First, we download the directory data using the Urban Institute’s API. These data include the districts and their &lt;a href=&#34;https://nces.ed.gov/pubs2007/ruraled/exhibit_a.asp&#34;&gt;urban-centric_locale&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccd_dir &amp;lt;- get_education_data(level = &amp;#39;school-districts&amp;#39;,
                              source = &amp;#39;ccd&amp;#39;, 
                              topic = &amp;#39;directory&amp;#39;, 
                              filters = list(year = 2016),
                              add_labels = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because there are so many options for urban-centric locale, let’s collapse them to just the biggest buckets: City, Town, Rural, and Suburb.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccd_urbanicity &amp;lt;-
  ccd_dir %&amp;gt;% 
  select(leaid, urban_centric_locale) %&amp;gt;% 
  mutate(leaid = as.numeric(leaid), # the enrollment file loads these as numeric
         geography = case_when(str_detect(urban_centric_locale, &amp;quot;City|city&amp;quot;) ~ &amp;quot;City&amp;quot;,
                               str_detect(urban_centric_locale, &amp;quot;Town|town&amp;quot;) ~ &amp;quot;Town&amp;quot;,
                               str_detect(urban_centric_locale, &amp;quot;Rural|rural&amp;quot;) ~ &amp;quot;Rural&amp;quot;,
                               str_detect(urban_centric_locale, &amp;quot;Suburb|suburb&amp;quot;) ~ &amp;quot;Suburb&amp;quot;)) %&amp;gt;% 
  select(-urban_centric_locale)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;size-raceethnicity-buckets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Size &amp;amp; Race/Ethnicity Buckets&lt;/h3&gt;
&lt;p&gt;Then, we download the enrollment data from the Urban Institute.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccd_enroll &amp;lt;- get_education_data(level = &amp;#39;school-districts&amp;#39;,
                                 source = &amp;#39;ccd&amp;#39;, 
                                 topic = &amp;#39;enrollment&amp;#39;, 
                                 filters = list(year = 2016,
                                             grade = 99),
                                 by = list(&amp;#39;race&amp;#39;),
                                 add_labels = TRUE) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We want to create two buckets here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Size:&lt;/strong&gt; Bucket districts by enrollment size, Small (less than 2500 students), Medium (between 2500 and 10,000 students), or Large (10,000 students or more). I used &lt;a href=&#34;https://www.google.com/search?q=what+is+a+large+school+district&amp;amp;oq=what+is+a&amp;amp;aqs=chrome.0.69i59j69i57j35i39j69i60l3.1065j0j7&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&#34;&gt;MDR’s&lt;/a&gt; definition for this.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Race/Ethnicity:&lt;/strong&gt; Bucket districts by Majority Non-White (50% or fewer of students are White) or Majority White (more than 50% of students are White).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccd_enroll_buckets &amp;lt;-
  ccd_enroll %&amp;gt;% 
  select(leaid, race, enrollment) %&amp;gt;% 
  spread(race, enrollment, -1) %&amp;gt;%
  mutate(white_na = case_when(White == 0 ~ NA_real_, # districts with missing data loaded as 0 instead of NA for some reason
                              TRUE ~ White),
         pct_white = white_na/Total,
         enroll_na = case_when(Total &amp;lt; 0 ~ NA_real_, # districts with missing data loaded as 0 instead of NA for some reason
                               TRUE ~ Total)) %&amp;gt;% 
  mutate(demographics = case_when(pct_white &amp;gt;= .5 ~ &amp;quot;Majority White&amp;quot;,
                                  pct_white &amp;lt; .5 ~ &amp;quot;Majority Non-White&amp;quot;,
                                  TRUE ~ NA_character_),
         size = case_when(enroll_na &amp;gt;= 10000 ~ &amp;quot;Large&amp;quot;,
                          enroll_na &amp;lt; 10000 &amp;amp; enroll_na &amp;gt;= 2500 ~ &amp;quot;Medium&amp;quot;,
                          enroll_na &amp;lt; 2500 ~ &amp;quot;Small&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;freereduced-price-lunch-bucket&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Free/Reduced Price Lunch Bucket&lt;/h3&gt;
&lt;p&gt;Now, we load the FRPL data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccd_frpl &amp;lt;-
  read_csv(here::here(&amp;quot;content&amp;quot;, &amp;quot;blog&amp;quot;, &amp;quot;modal_district_files&amp;quot;, &amp;quot;ccd_sch_033_1617_l_2a_11212017.csv&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We want Free + Reduced Price Lunch numbers by district. This file also has Free Lunch and Reduced Lunch numbers, and it is school-level. We aggregate up Free + Reduced Price Lunch by district.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccd_frpl_wide &amp;lt;-
  ccd_frpl %&amp;gt;% 
  clean_names() %&amp;gt;% 
  mutate(leaid = as.numeric(leaid)) %&amp;gt;% 
  filter(data_group == &amp;quot;Free and Reduced-price Lunch Table&amp;quot;,
         lunch_program == &amp;quot;No Category Codes&amp;quot;) %&amp;gt;% 
  select(leaid, student_count) %&amp;gt;% 
  group_by(leaid) %&amp;gt;% 
  summarise(frpl_student_count = sum(student_count))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, we merge with the enrollment data to calculate percent FRPL by district. Our buckets are Low FRPL (less than 25%), Medium-Low FRPL (between 25% and 50% FRPL), Medium-High FRPL (between 50% and 75% FRPL), and High FRPL (greater than 75% FRPL). I originally did not have Medium-Low and Medium High split out but that bucket was so large that I thought this would bring more nuance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccd_enroll_buckets &amp;lt;-
  left_join(ccd_enroll_buckets, ccd_frpl_wide) %&amp;gt;% 
  mutate(pct_frpl = frpl_student_count/enroll_na,
         frpl = case_when(pct_frpl &amp;lt;= .25 ~ &amp;quot;Low FRPL&amp;quot;,
                          pct_frpl &amp;gt; .25 &amp;amp; pct_frpl &amp;lt;= .5 ~ &amp;quot;Medium-Low FRPL&amp;quot;,
                          pct_frpl &amp;gt; .5 &amp;amp; pct_frpl &amp;lt;= .75 ~ &amp;quot;Medium-High FRPL&amp;quot;,
                          pct_frpl &amp;gt; .75 ~ &amp;quot;High FRPL&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bringing-it-all-together&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bringing It All Together&lt;/h3&gt;
&lt;p&gt;Finally, we put all the datasets together. One question raised was what to do with missing data. Some districts, either because of small n-sizes or policy, do not report their demographic or FRPL numbers. In fact, some districts were missing enrollment data altogether! For the purposes of this analysis, I removed any district that was missing data in the FRPL or Race/Ethnicity Buckets. Any data without enrollment data is also excluded.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccd_all &amp;lt;-
  full_join(ccd_urbanicity, ccd_enroll_buckets, by = &amp;quot;leaid&amp;quot;) %&amp;gt;% 
  filter(!is.na(frpl),
         !is.na(demographics))

ccd_all &amp;lt;- # reordering factors
  ccd_all %&amp;gt;% 
  mutate(demographics = factor(demographics, c(&amp;quot;Majority White&amp;quot;, &amp;quot;Majority Non-White&amp;quot;)),
         size = factor(size, c(&amp;quot;Small&amp;quot;, &amp;quot;Medium&amp;quot;, &amp;quot;Large&amp;quot;)),
         geography = factor(geography, c(&amp;quot;Rural&amp;quot;, &amp;quot;Suburb&amp;quot;, &amp;quot;Town&amp;quot;, &amp;quot;City&amp;quot;)),
         frpl = factor(frpl, c(&amp;quot;Low FRPL&amp;quot;, &amp;quot;Medium-Low FRPL&amp;quot;, &amp;quot;Medium-High FRPL&amp;quot;, &amp;quot;High FRPL&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;running-the-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Running the Analysis&lt;/h3&gt;
&lt;p&gt;We can see what is the modal school district - that is, the combination of our buckets that represents the most districts in the U.S.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 2019-09-18:&lt;/strong&gt; Thanks to the input from &lt;a href=&#34;https://twitter.com/apreshill&#34;&gt;Alison Hill&lt;/a&gt; on Twitter, instead of the &lt;code&gt;grouper()&lt;/code&gt; function in the original analysis I’m using &lt;code&gt;dplyr::count()&lt;/code&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;This is a great post! I think you don&amp;#39;t need the grouper function- I think what you need is dplyr::count(sort = TRUE) (it also does the ungroup for you :) &lt;a href=&#34;https://t.co/G6ccoQIHFC&#34;&gt;https://t.co/G6ccoQIHFC&lt;/a&gt;&lt;/p&gt;&amp;mdash; Alison Presmanes Hill (@apreshill) &lt;a href=&#34;https://twitter.com/apreshill/status/1174152252996501504?ref_src=twsrc%5Etfw&#34;&gt;September 18, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;
&lt;p&gt;The n shows how many districts fit these criteria. Here are the first four but the full table is in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modal &amp;lt;- 
  ccd_all %&amp;gt;% 
  count(demographics, frpl, geography, size, sort = TRUE)

modal %&amp;gt;% 
  top_n(4) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;demographics&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;frpl&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;geography&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;size&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2484&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1572&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;888&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;689&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The modal school district ends up being: Majority White, Rural, Small, Medium-Low FRPL districts. &lt;strong&gt;18%&lt;/strong&gt; (2484) of the 13,464 districts in our analysis fall within these criteria.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;takeaways&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Takeaways&lt;/h2&gt;
&lt;div id=&#34;some-districts-are-all-alike-every-district-is-different-in-its-own-way&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Some districts are all alike; every district is different in its own way&lt;/h3&gt;
&lt;p&gt;If you run each bucket individually, you get the same results as all of the groups together (as in, when running only based on size, the result is that Rural districts are the modal districts). This is slightly different from the Modal American analysis from NPR - none of these demographics seem to ‘split’ the groups.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;this-makes-sense&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;This makes sense&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The U.S. is majority White and areas tend to be segregated.&lt;/li&gt;
&lt;li&gt;Majority of districts fall in the Medium FRPL buckets. Majority Non-White districts tend to have higher levels of FRPL, but there are so few of them compared to Majority White Districts, that they do not change the modal district much.&lt;/li&gt;
&lt;li&gt;The U.S. is very large and districts cannot get too geographically big in order to serve their students. In places with little population density, which is most of the U.S., these districts must remain small.&lt;/li&gt;
&lt;li&gt;Similarly, there are not that many Cities/Towns compared to Rural districts, probably because you need many districts in Rural areas to serve the spread-out population of students.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;its-really-hard-to-visualize-this&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;It’s really hard to visualize this&lt;/h3&gt;
&lt;p&gt;It was interesting trying to visualize these data, especially since there ended up being 87 (!) combinations. I tried a Sankey chart but it is a bit bananas.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(as.data.frame(modal),
       aes(y = n,
           axis1 = demographics, 
           axis2 = geography, 
           axis3 = frpl,
           axis4 = size)) +
  stat_alluvium(aes(fill = n),
                width = 1/6, 
            alpha = 2/3,
            aes.bind = FALSE) +
  guides(fill = FALSE) +
  geom_stratum(width = 1/12, fill = &amp;quot;black&amp;quot;, color = &amp;quot;grey&amp;quot;) +
  geom_label(stat = &amp;quot;stratum&amp;quot;, label.strata = TRUE, size = 2, hjust = &amp;quot;inward&amp;quot;) +
  scale_x_continuous(breaks = 1:4, labels = c(&amp;quot;Demographics&amp;quot;, &amp;quot;Geography&amp;quot;, &amp;quot;FRPL&amp;quot;, &amp;quot;Size&amp;quot;)) +
  ggtitle(&amp;quot;Modal District Sankey Chart&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/modal-district_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I tried to visualize the data another way - using bar plots. Again, this gets a bit unruly with all the variables. This leads me to think it’s better to just look at the table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccd_all %&amp;gt;% 
  select(leaid, demographics, geography, size, frpl) %&amp;gt;% 
  mutate(count = 1) %&amp;gt;% 
  ggplot(aes(count)) +
  geom_bar() +
  facet_grid(demographics + frpl ~ size + geography)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/modal-district_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Next steps&lt;/h2&gt;
&lt;p&gt;In addition to analyzing more variables (perhaps data that are less likely to correlate), it would be interesting to cut the data using smaller grain size for the buckets. There are probably very interesting nuances between Majority White districts for example - we just need the data (and bandwidth!) to find out.&lt;/p&gt;
&lt;p&gt;I am in awe of social media, which allows us to learn and share in so many ways. My friend retweeted a news article, which prompted the person who wrote the code to share, and then we crafted an idea based on that. I think that’s pretty great!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 2019-09-18:&lt;/strong&gt; &lt;a href=&#34;https://twitter.com/bencasselman&#34;&gt;Ben Casselman&lt;/a&gt; wrote a reply on how it would be interesting to conduct an analysis on the modal school experience. So exciting! Can’t wait to continue the analysis (and always looking for collaborators!)&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Curious what this would look like if you weighted by student population -- in essence, the modal school *experience.* (More students attend this type of school than any other.) Suspect the results would look quite different.&lt;/p&gt;&amp;mdash; Ben Casselman (@bencasselman) &lt;a href=&#34;https://twitter.com/bencasselman/status/1173577230997512198?ref_src=twsrc%5Etfw&#34;&gt;September 16, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Appendix&lt;/h2&gt;
&lt;div id=&#34;full-table&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Full Table&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ccd_all %&amp;gt;% 
  count(demographics, frpl, geography, size) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;demographics&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;frpl&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;geography&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;size&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;888&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;520&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;434&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;156&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;39&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;102&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2484&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;115&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;343&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;260&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;52&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;604&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;163&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;83&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1572&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;106&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;151&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;447&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;154&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;57&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;340&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;28&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;47&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;59&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;101&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;111&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-Low FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;275&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;159&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;134&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;54&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;130&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;63&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;261&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium-High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;102&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;454&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;184&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;82&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Suburb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;167&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;90&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Town&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Small&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;689&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Medium&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;44&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Majority Non-White&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;High FRPL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;City&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Large&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;63&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Taking A Peek into My Hiking Data</title>
      <link>/blog/average-hike/</link>
      <pubDate>Sat, 06 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/average-hike/</guid>
      <description>


&lt;p&gt;I moved to Seattle at the end of 2016 and since then have done over 100 hikes (depending on your definition of ‘a hike’!). I must admit I’ve been abysmal at tracking any data regarding my hiking activity beyond a &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1Y3NdGea6yVuoDS7ewUKmuKGZouzU62FHK-aY813TafA/edit?usp=sharing&#34;&gt;Google spreadsheet&lt;/a&gt;, despite the ubiquity of trail tracking apps that exist.&lt;/p&gt;
&lt;p&gt;Recently, I signed up on &lt;a href=&#34;https://www.alltrails.com/&#34;&gt;AllTrails&lt;/a&gt; to start collecting data on my hikes. The Pro service offers many wonderful features, including the ability to download GPX data on hikes. I was so excited by this that I decided to try to visualize the hikes I have done.&lt;/p&gt;
&lt;p&gt;I’m structuring this article a bit differently with the results/visualizations first, but for anybody dying to see the data cleaning process, please see the &lt;a href=&#34;#methodology&#34;&gt;Methodology&lt;/a&gt; or &lt;a href=&#34;#viz&#34;&gt;Visualizations&lt;/a&gt; sections below! (Interesting, I ran &lt;a href=&#34;https://twitter.com/ivelasq3/status/1121536896956428289&#34;&gt;a poll on Twitter&lt;/a&gt; in which I asked whether people embed code in the main text of their blog post or at the end. 91% embed in the main text [n = 85]! Still, I prefer having the code at the end).&lt;/p&gt;
&lt;div id=&#34;analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Analysis&lt;/h1&gt;
&lt;div id=&#34;disclaimer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;For data collection, I downloaded each trail’s GPX files from AllTrails. Because these data are proprietary, I will not be providing them. Some things to note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Because these are data pulled from the website, they are not indicative of my actual hiking path (for example, Franklin Falls is a 2 mile hike in the summer, but in the winter is a 6 mile snowshoe).&lt;/li&gt;
&lt;li&gt;There are hikes that I did back-to-back that I’d consider one hike but the trails might be listed separately on the site. For example, Deception Pass is actually made up of three small loops.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;the-hikes-are-wide-and-varied&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The hikes are wide and varied&lt;/h2&gt;
&lt;p&gt;Being fortunate enough to live near multiple mountain ranges, the hikes I’ve been on come in all shapes and sizes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/average-hike_files/joyplot.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I calculated my ‘average hike’ - that is, the average elevation given the cumulative distance travelled.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/average-hike_files/avg_hike.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;aggregated-data-by-trail&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Aggregated Data by Trail&lt;/h2&gt;
&lt;p&gt;In the aggregate, there seems to be a correlation (r^2 = 0.48) between total distance and total elevation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/average-hike_files/tot_dis_elev.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;there-exist-categories-of-hikes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;There Exist Categories of Hikes&lt;/h2&gt;
&lt;p&gt;I ran a quick &lt;a href=&#34;https://uc-r.github.io/kmeans_clustering&#34;&gt;cluster analysis&lt;/a&gt; to see if I can categorize my hikes in any way. Code is in the &lt;a href=&#34;#methodology&#34;&gt;Methodology&lt;/a&gt; section. Four clusters seemed to be optimal. I have dubbed them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cluster 1: “Let’s Get This Over With” (steep &amp;amp; hard)&lt;/li&gt;
&lt;li&gt;Cluster 2: “Easy Peasy Lemon Squeezy” (short &amp;amp; flat)&lt;/li&gt;
&lt;li&gt;Cluster 3: “The Sweet Spot” (not too long, not too high)&lt;/li&gt;
&lt;li&gt;Cluster 4: “I Don’t Care About My Knees Anyway” (too long for my own good)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/average-hike_files/cluster_analysis.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i-dont-particularly-love-long-hikes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I don’t particularly love long hikes&lt;/h2&gt;
&lt;p&gt;My average hike is 6.4 miles - and most of them are concentrated around that distance. This makes sense as I usually day hike and need to get back at a reasonable time. My shortest hike was 1.18 miles and my longest was 17.85 (the Enchantments…). In these 90 hikes, I hiked around 576 miles.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/average-hike_files/dist_histogram.png&#34; /&gt; &lt;img src=&#34;https://ivelasq.rbind.io/img/average-hike_files/cum_dist.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i-dont-dislike-high-elevation-hikes-though&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I don’t dislike high elevation hikes though&lt;/h2&gt;
&lt;p&gt;Elevation on these hikes ranged from ~0 feet to 4580 feet gain. I averaged 1455.4 feet gain and have climbed 130,984 feet (~24 miles!).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ivelasq.rbind.io/img/average-hike_files/elev_histogram.png&#34; /&gt; &lt;img src=&#34;https://ivelasq.rbind.io/img/average-hike_files/cum_elev.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;methodology&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Methodology&lt;/h1&gt;
&lt;div id=&#34;choose-packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Choose Packages&lt;/h2&gt;
&lt;p&gt;It took a bit to decide which packages had the functions needed to run the spatial analyses. In the end, I decided on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;plotKML&lt;/strong&gt;: A package containing functions to read GPX files.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;geosphere&lt;/strong&gt;: A package containing functions for geospatial calculations. I decided to use this for finding out distances between lon/lat.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;googleway&lt;/strong&gt;: A package allowing access to the Google Maps API. To run this, you need to obtain a Google Maps API key and load it to R by using &lt;code&gt;set_key()&lt;/code&gt;. I use this for elevation calculations but the API can also obtain distance between points.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(googleway)
library(plotKML)
library(geosphere)

googleway::set_key(API_KEY_HERE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;upload-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Upload Data&lt;/h2&gt;
&lt;p&gt;I downloaded each GPX file from AllTrails and saved them in a file in my project organization. Their file names were TRAILNAME.gpx.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using &lt;code&gt;plotKML::readGPX()&lt;/code&gt; results in the files being loaded as lists.&lt;/li&gt;
&lt;li&gt;I used &lt;code&gt;purrr&lt;/code&gt; in conjunction with &lt;code&gt;plotKML()&lt;/code&gt; to handily read them in and add the file name to the list.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# find gpx files
data_path &amp;lt;- 
  here::here(&amp;quot;data&amp;quot;, &amp;quot;raw&amp;quot;, &amp;quot;gpx_files&amp;quot;)

files &amp;lt;-
  dir(data_path, pattern = &amp;quot;*.gpx&amp;quot;, full.names = TRUE)

# get trail names
names &amp;lt;-
  dir(data_path, pattern = &amp;quot;*.gpx&amp;quot;, full.names = FALSE) %&amp;gt;% 
  str_extract(&amp;quot;.+?(?=.gpx)&amp;quot;)

# read all gpx files
gpx_dat &amp;lt;-
  map2(files,
       names,
       ~ readGPX(.x,
         metadata = TRUE,
         bounds = TRUE,
         waypoints = TRUE,
         tracks = TRUE,
         routes = TRUE) %&amp;gt;%
         list_modify(trail = .y)) # otherwise you can&amp;#39;t tell which entry is for which trail&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-elevation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculate Elevation&lt;/h2&gt;
&lt;p&gt;We can use &lt;code&gt;googleway::google_elevation()&lt;/code&gt; to access the Google Elevation API and calculate elevation for every lon/lat pair from the GPX files. Unfortunately, the API accepts and returns only a few requests at a time (~200 rows for these files). We have over 51,000 rows of data. So, we can create groups for every 200 rows and use a loop to make a call for each&lt;/p&gt;
&lt;p&gt;This results in a list, so we can then create a tibble pulling out the data we want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lonlat_dat &amp;lt;-
  gpx_dat %&amp;gt;%
  map_df(., ~.x$&amp;quot;routes&amp;quot;[[1]], .id = &amp;quot;trail&amp;quot;) %&amp;gt;%
  select(trail, lon, lat) %&amp;gt;% 
  group_by(trail) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(group_number = (1:nrow(.) %/% 200) + 1) # https://stackoverflow.com/questions/32078578/how-to-group-by-every-7-rows-and-aggregate-those-7-values-by-median

dat_lapply &amp;lt;- lapply(1:max(lonlat_dat$group_number), function(x) {
  Sys.sleep(3)
  
  lonlat_dat %&amp;gt;%
    filter(group_number == x) %&amp;gt;% # added a filter so you only pull a subset of the data.
    do(elev_dat =
         data.frame(
           google_elevation(
             df_locations = dplyr::select(., lon, lat),
             location_type = &amp;quot;individual&amp;quot;,
             simplify = TRUE)))
  })

dat_lapply_elev_dat &amp;lt;-
  dat_lapply %&amp;gt;%
  map(., ~ .x$&amp;quot;elev_dat&amp;quot;[[1]])

elev_df &amp;lt;-
  dat_lapply_elev_dat %&amp;gt;% {
    tibble(
      elevation = map(., ~ .x$&amp;quot;results.elevation&amp;quot;),
      lon = map(., ~ .x$&amp;quot;results.location&amp;quot;[[&amp;quot;lng&amp;quot;]]),
      lat = map(.,  ~ .x$&amp;quot;results.location&amp;quot;[[&amp;quot;lat&amp;quot;]])
    )
  } %&amp;gt;% 
  unnest(.id = &amp;quot;group_number&amp;quot;) %&amp;gt;% 
  select(group_number, elevation, lon, lat)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-distance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculate Distance&lt;/h2&gt;
&lt;p&gt;Now we have a list of trails, longitudes and latitudes along their paths, and the elevation for each of those points. Now we want to calculate the distance along the paths.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We bring back &lt;code&gt;lonlat_dat&lt;/code&gt; so we know what trails with which each points are associated.&lt;/li&gt;
&lt;li&gt;To use calculate distance, we can use &lt;code&gt;distHaversine()&lt;/code&gt; with two sets of lon/lat. We create the second set of lon/lat by creating a new variable that takes the “next” value in a vector (so we’re calculating the distance between point A and point B, point B to point C, and so on).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cumsum()&lt;/code&gt; accumulates the distances between each set of lon/lat.&lt;/li&gt;
&lt;li&gt;Finally, we calculate the elevation gain for each hike.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hiking_dat &amp;lt;-
  plyr::join(elev_df, lonlat_dat, type = &amp;quot;left&amp;quot;, match = &amp;quot;first&amp;quot;) %&amp;gt;% 
  group_by(trail) %&amp;gt;% 
  mutate(elev_feet = elevation * 3.281, # to convert to feet
         lon2 = lead(lon, 1),
         lat2 = lead(lat, 1)) %&amp;gt;%
  ungroup() %&amp;gt;% 
  mutate(dist = distHaversine(hiking_dat[, 2:3], hiking_dat[, 7:8])/1609.344) %&amp;gt;% # to convert to miles
  group_by(trail) %&amp;gt;% 
  mutate(cumdist = cumsum(dist),
         elev_gain = elev_feet - first(elev_feet)) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;create-additional-tables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create Additional Tables&lt;/h2&gt;
&lt;p&gt;For nerdy kicks, I also wanted to find out my ‘average’ hike - that is, the average distance, the average elevation, and the average elevation for each distance. I also wanted to see the total distance and elevation for each trail for which I pulled data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avg_elev &amp;lt;- # average elevation by distance
  hiking_dat %&amp;gt;% 
  group_by(round(cumdist, 1)) %&amp;gt;% 
  summarize(mean(elev_gain))

hiking_dat_by_trail &amp;lt;- # total gain/distance by trail
  hiking_dat %&amp;gt;% 
  select(trail, cumdist, elev_gain) %&amp;gt;% 
  group_by(trail) %&amp;gt;%
  summarize(tot_dist = max(cumdist, na.rm = T),
            tot_elev_gain = max(elev_gain)) %&amp;gt;% 
  mutate(tot_dist_scaled = scale(tot_dist), # for cluster analysis
         tot_elev_scaled = scale(tot_elev_gain))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;viz&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Visualizations&lt;/h1&gt;
&lt;p&gt;Below is the code for the visualizations presented above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(viridis)
library(ggridges)
library(cluster)
library(factoextra)

# joy plot

ggplot() + 
  geom_density_ridges(data = na.omit(hiking_dat),
                      aes(x = cumdist,
                          y = trail,
                          group = trail),
                      fill = &amp;quot;#00204c&amp;quot;,
                      rel_min_height = 0.01
                      ) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)

# average hike

ggplot() + 
  geom_ridgeline(data = hiking_dat,
                 aes(x = cumdist,
                     y = trail,
                     group = trail,
                     height = elev_gain),
                 color = &amp;quot;#c9b869&amp;quot;,
                 alpha = 0) +
  geom_line(data = avg_elev,
            aes(x = `round(cumdist, 1)`,
                y = `mean(elev_gain)`),
            color = &amp;quot;#00204c&amp;quot;,
            size = 2) +
  scale_x_continuous(name = &amp;quot;Cumulative Distance (miles)&amp;quot;) +
  scale_y_continuous(name = &amp;quot;Cumulative Elevation (ft)&amp;quot;, limits = c(0, 5000)) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)

# aggregate data scatterplot

ggplot() + 
  geom_point(data = hiking_dat_by_trail,
             aes(x = tot_dist,
                 y = tot_elev_gain,
                 color = tot_elev_gain,
                 size = tot_dist)) +
  scale_x_continuous(name = &amp;quot;Total Distance (miles)&amp;quot;) +
  scale_y_continuous(name = &amp;quot;Total Elevation (ft)&amp;quot;) +
  scale_color_viridis(option = &amp;quot;cividis&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)

# cluster analysis

fviz_nbclust(hiking_dat_by_trail[, 4:5], kmeans, method = &amp;quot;wss&amp;quot;) # finding optimal number of clusters
k4 &amp;lt;- kmeans(hiking_dat_by_trail[, 4:5], centers = 4, nstart = 25) # calculating clusters

fviz_cluster(k4, data = hiking_dat_by_trail)  +
  scale_x_continuous(name = &amp;quot;Scaled Total Distance (miles)&amp;quot;) +
  scale_y_continuous(name = &amp;quot;Scaled Total Elevation (ft)&amp;quot;) +
  scale_color_viridis(option = &amp;quot;cividis&amp;quot;, discrete = T) +
  scale_fill_viridis(option = &amp;quot;cividis&amp;quot;, discrete = T) +
  theme_minimal()

#  cumulative distance barplot

hiking_dat_by_trail %&amp;gt;% 
  mutate(cumdist = cumsum(tot_dist)) %&amp;gt;% 
  ggplot(aes(x = trail,
             y = cumdist,
             fill = cumdist)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;) +
  scale_fill_viridis(option = &amp;quot;cividis&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)

# distance histogram

hiking_dat_by_trail %&amp;gt;% 
  ggplot(aes(x = tot_dist)) +
  geom_histogram(fill = &amp;quot;#00204c&amp;quot;) +
  xlab(&amp;quot;Trail Total Distance (miles)&amp;quot;) +
  ylab(&amp;quot;Count&amp;quot;) +
  scale_fill_viridis(option = &amp;quot;cividis&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)

# cumulative elevation barplot

hiking_dat_by_trail %&amp;gt;% 
  mutate(cumelev = cumsum(tot_elev_gain)) %&amp;gt;% 
  ggplot(aes(x = trail,
             y = cumelev,
             fill = cumelev)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;) +
  scale_fill_viridis(option = &amp;quot;cividis&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)

# elevation histogram

hiking_dat_by_trail %&amp;gt;% 
  ggplot(aes(x = tot_elev_gain)) +
  geom_histogram(fill = &amp;quot;#00204c&amp;quot;) +
  xlab(&amp;quot;Trail Total Elevation (ft)&amp;quot;) +
  ylab(&amp;quot;Count&amp;quot;) +
  scale_fill_viridis(option = &amp;quot;cividis&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
